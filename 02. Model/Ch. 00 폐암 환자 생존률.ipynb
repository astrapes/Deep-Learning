{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 ,   2.8 ,   0.  ,   0.  ,   0.  ,   0.  ,\n",
       "          0.  ,   0.  ,  12.  ,   0.  ,   0.  ,   0.  ,   1.  ,   0.  ,\n",
       "         62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88,   2.16,   1.  ,   0.  ,   0.  ,   0.  ,\n",
       "          1.  ,   1.  ,  14.  ,   0.  ,   0.  ,   0.  ,   1.  ,   0.  ,\n",
       "         60.  ,   0.  ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 준비된 수술 환자 데이터를 불러들임\n",
    "data_set=np.loadtxt(\"../dataset/ThoraricSurgery.csv\",delimiter=\",\")\n",
    "data_set[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환자의 기록과 수술 결과를 X와 Y로 구분하여 저장\n",
    "X=data_set[:,0:17]\n",
    "Y=data_set[:,17]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                540       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델 설정\n",
    "# Input 17개, Hidden layer 30개, Output 0 or 1\n",
    "model=Sequential([\n",
    "    Dense(30,input_shape=(17,), activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 환경 설정 (오차함수, 최적화 함수)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 76 samples\n",
      "Epoch 1/500\n",
      "300/300 [==============================] - 0s 1ms/sample - loss: 7.0827 - accuracy: 0.5567 - val_loss: 2.6455 - val_accuracy: 0.8421\n",
      "Epoch 2/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 2.6735 - accuracy: 0.8300 - val_loss: 2.0417 - val_accuracy: 0.8421\n",
      "Epoch 3/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 1.7036 - accuracy: 0.7867 - val_loss: 1.0925 - val_accuracy: 0.8158\n",
      "Epoch 4/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 1.0296 - accuracy: 0.7733 - val_loss: 0.6262 - val_accuracy: 0.8026\n",
      "Epoch 5/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.6762 - accuracy: 0.8033 - val_loss: 0.6879 - val_accuracy: 0.8158\n",
      "Epoch 6/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.5982 - accuracy: 0.8133 - val_loss: 0.5405 - val_accuracy: 0.7368\n",
      "Epoch 7/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.5585 - accuracy: 0.8133 - val_loss: 0.5407 - val_accuracy: 0.8289\n",
      "Epoch 8/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.5166 - accuracy: 0.8300 - val_loss: 0.4722 - val_accuracy: 0.8289\n",
      "Epoch 9/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.5053 - accuracy: 0.8300 - val_loss: 0.4722 - val_accuracy: 0.8289\n",
      "Epoch 10/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.5039 - accuracy: 0.8233 - val_loss: 0.4855 - val_accuracy: 0.8289\n",
      "Epoch 11/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.4658 - accuracy: 0.8400 - val_loss: 0.4477 - val_accuracy: 0.8421\n",
      "Epoch 12/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4844 - accuracy: 0.8467 - val_loss: 0.4720 - val_accuracy: 0.8421\n",
      "Epoch 13/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4738 - accuracy: 0.8400 - val_loss: 0.4605 - val_accuracy: 0.8421\n",
      "Epoch 14/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4562 - accuracy: 0.8367 - val_loss: 0.5116 - val_accuracy: 0.8421\n",
      "Epoch 15/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4644 - accuracy: 0.8533 - val_loss: 0.4650 - val_accuracy: 0.8289\n",
      "Epoch 16/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4628 - accuracy: 0.8500 - val_loss: 0.5035 - val_accuracy: 0.8421\n",
      "Epoch 17/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4476 - accuracy: 0.8533 - val_loss: 0.4624 - val_accuracy: 0.8421\n",
      "Epoch 18/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4467 - accuracy: 0.8500 - val_loss: 0.4598 - val_accuracy: 0.8421\n",
      "Epoch 19/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4438 - accuracy: 0.8533 - val_loss: 0.4932 - val_accuracy: 0.8421\n",
      "Epoch 20/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4546 - accuracy: 0.8467 - val_loss: 0.6682 - val_accuracy: 0.8421\n",
      "Epoch 21/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.4638 - accuracy: 0.8467 - val_loss: 0.4619 - val_accuracy: 0.8421\n",
      "Epoch 22/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4442 - accuracy: 0.8433 - val_loss: 0.4576 - val_accuracy: 0.8289\n",
      "Epoch 23/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4463 - accuracy: 0.8567 - val_loss: 0.4841 - val_accuracy: 0.8421\n",
      "Epoch 24/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4355 - accuracy: 0.8500 - val_loss: 0.4317 - val_accuracy: 0.8421\n",
      "Epoch 25/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4336 - accuracy: 0.8533 - val_loss: 0.4452 - val_accuracy: 0.8289\n",
      "Epoch 26/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4630 - accuracy: 0.8467 - val_loss: 0.4740 - val_accuracy: 0.8421\n",
      "Epoch 27/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.5250 - accuracy: 0.8233 - val_loss: 0.5758 - val_accuracy: 0.8421\n",
      "Epoch 28/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4126 - accuracy: 0.8400 - val_loss: 0.6429 - val_accuracy: 0.8421\n",
      "Epoch 29/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.5034 - accuracy: 0.8333 - val_loss: 0.6387 - val_accuracy: 0.6711\n",
      "Epoch 30/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4477 - accuracy: 0.8533 - val_loss: 0.5005 - val_accuracy: 0.8421\n",
      "Epoch 31/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4531 - accuracy: 0.8533 - val_loss: 0.4406 - val_accuracy: 0.8421\n",
      "Epoch 32/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4771 - accuracy: 0.8533 - val_loss: 0.5054 - val_accuracy: 0.8421\n",
      "Epoch 33/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4252 - accuracy: 0.8600 - val_loss: 0.4558 - val_accuracy: 0.8289\n",
      "Epoch 34/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.4149 - accuracy: 0.8567 - val_loss: 0.5383 - val_accuracy: 0.8421\n",
      "Epoch 35/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.4115 - accuracy: 0.8500 - val_loss: 0.4567 - val_accuracy: 0.8289\n",
      "Epoch 36/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4107 - accuracy: 0.8567 - val_loss: 0.4488 - val_accuracy: 0.8289\n",
      "Epoch 37/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.3865 - accuracy: 0.8600 - val_loss: 0.4881 - val_accuracy: 0.8421\n",
      "Epoch 38/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4383 - accuracy: 0.8600 - val_loss: 0.4806 - val_accuracy: 0.8421\n",
      "Epoch 39/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4189 - accuracy: 0.8567 - val_loss: 0.5921 - val_accuracy: 0.8421\n",
      "Epoch 40/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4481 - accuracy: 0.8633 - val_loss: 0.4718 - val_accuracy: 0.8289\n",
      "Epoch 41/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4121 - accuracy: 0.8600 - val_loss: 0.5266 - val_accuracy: 0.8421\n",
      "Epoch 42/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4157 - accuracy: 0.8533 - val_loss: 0.4481 - val_accuracy: 0.8289\n",
      "Epoch 43/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4029 - accuracy: 0.8533 - val_loss: 0.4766 - val_accuracy: 0.8289\n",
      "Epoch 44/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4239 - accuracy: 0.8533 - val_loss: 0.4603 - val_accuracy: 0.8289\n",
      "Epoch 45/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4320 - accuracy: 0.8533 - val_loss: 0.4721 - val_accuracy: 0.8289\n",
      "Epoch 46/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3981 - accuracy: 0.8533 - val_loss: 0.4810 - val_accuracy: 0.8421\n",
      "Epoch 47/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3969 - accuracy: 0.8567 - val_loss: 0.4553 - val_accuracy: 0.8289\n",
      "Epoch 48/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4194 - accuracy: 0.8500 - val_loss: 0.4723 - val_accuracy: 0.8289\n",
      "Epoch 49/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4966 - accuracy: 0.8533 - val_loss: 0.4903 - val_accuracy: 0.8289\n",
      "Epoch 50/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4275 - accuracy: 0.8433 - val_loss: 0.4717 - val_accuracy: 0.8158\n",
      "Epoch 51/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4338 - accuracy: 0.8500 - val_loss: 0.4761 - val_accuracy: 0.8289\n",
      "Epoch 52/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4072 - accuracy: 0.8533 - val_loss: 0.4649 - val_accuracy: 0.8289\n",
      "Epoch 53/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4244 - accuracy: 0.8433 - val_loss: 0.6278 - val_accuracy: 0.8421\n",
      "Epoch 54/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4023 - accuracy: 0.8567 - val_loss: 0.4910 - val_accuracy: 0.8158\n",
      "Epoch 55/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4052 - accuracy: 0.8567 - val_loss: 0.6431 - val_accuracy: 0.8421\n",
      "Epoch 56/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4497 - accuracy: 0.8500 - val_loss: 0.4801 - val_accuracy: 0.8026\n",
      "Epoch 57/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4040 - accuracy: 0.8567 - val_loss: 0.4725 - val_accuracy: 0.8289\n",
      "Epoch 58/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4360 - accuracy: 0.8433 - val_loss: 0.4657 - val_accuracy: 0.8289\n",
      "Epoch 59/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4369 - accuracy: 0.8533 - val_loss: 0.5134 - val_accuracy: 0.8289\n",
      "Epoch 60/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.4007 - accuracy: 0.8567 - val_loss: 0.5726 - val_accuracy: 0.8421\n",
      "Epoch 61/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4167 - accuracy: 0.8400 - val_loss: 0.5033 - val_accuracy: 0.8289\n",
      "Epoch 62/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3983 - accuracy: 0.8600 - val_loss: 0.4735 - val_accuracy: 0.8289\n",
      "Epoch 63/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4085 - accuracy: 0.8633 - val_loss: 0.5883 - val_accuracy: 0.8421\n",
      "Epoch 64/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4064 - accuracy: 0.8500 - val_loss: 0.4878 - val_accuracy: 0.8289\n",
      "Epoch 65/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4028 - accuracy: 0.8467 - val_loss: 0.4822 - val_accuracy: 0.8289\n",
      "Epoch 66/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3836 - accuracy: 0.8533 - val_loss: 0.5309 - val_accuracy: 0.7763\n",
      "Epoch 67/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4686 - accuracy: 0.8200 - val_loss: 0.5879 - val_accuracy: 0.8421\n",
      "Epoch 68/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.3970 - accuracy: 0.8600 - val_loss: 0.4546 - val_accuracy: 0.8289\n",
      "Epoch 69/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3836 - accuracy: 0.8500 - val_loss: 0.4874 - val_accuracy: 0.8289\n",
      "Epoch 70/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3902 - accuracy: 0.8433 - val_loss: 0.4671 - val_accuracy: 0.8289\n",
      "Epoch 71/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.5049 - accuracy: 0.8233 - val_loss: 0.5137 - val_accuracy: 0.8289\n",
      "Epoch 72/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4355 - accuracy: 0.8367 - val_loss: 0.5098 - val_accuracy: 0.8158\n",
      "Epoch 73/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4019 - accuracy: 0.8433 - val_loss: 0.4808 - val_accuracy: 0.8289\n",
      "Epoch 74/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3933 - accuracy: 0.8533 - val_loss: 0.5332 - val_accuracy: 0.8289\n",
      "Epoch 75/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3858 - accuracy: 0.8533 - val_loss: 0.5075 - val_accuracy: 0.8289\n",
      "Epoch 76/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4250 - accuracy: 0.8400 - val_loss: 0.4808 - val_accuracy: 0.8289\n",
      "Epoch 77/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4196 - accuracy: 0.8367 - val_loss: 0.5330 - val_accuracy: 0.8289\n",
      "Epoch 78/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3863 - accuracy: 0.8533 - val_loss: 0.4700 - val_accuracy: 0.8289\n",
      "Epoch 79/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3984 - accuracy: 0.8467 - val_loss: 0.5275 - val_accuracy: 0.8026\n",
      "Epoch 80/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4848 - accuracy: 0.8533 - val_loss: 0.7246 - val_accuracy: 0.8421\n",
      "Epoch 81/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4201 - accuracy: 0.8500 - val_loss: 0.4571 - val_accuracy: 0.8289\n",
      "Epoch 82/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3876 - accuracy: 0.8533 - val_loss: 0.4897 - val_accuracy: 0.8289\n",
      "Epoch 83/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4477 - accuracy: 0.8533 - val_loss: 0.5464 - val_accuracy: 0.8289\n",
      "Epoch 84/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4054 - accuracy: 0.8267 - val_loss: 0.4695 - val_accuracy: 0.8289\n",
      "Epoch 85/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3996 - accuracy: 0.8500 - val_loss: 0.4747 - val_accuracy: 0.8421\n",
      "Epoch 86/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3950 - accuracy: 0.8367 - val_loss: 0.6820 - val_accuracy: 0.8421\n",
      "Epoch 87/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4204 - accuracy: 0.8500 - val_loss: 0.4781 - val_accuracy: 0.8289\n",
      "Epoch 88/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3746 - accuracy: 0.8500 - val_loss: 0.5738 - val_accuracy: 0.8289\n",
      "Epoch 89/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4098 - accuracy: 0.8533 - val_loss: 0.5068 - val_accuracy: 0.8289\n",
      "Epoch 90/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.3809 - accuracy: 0.8500 - val_loss: 0.5841 - val_accuracy: 0.6974\n",
      "Epoch 91/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4566 - accuracy: 0.8400 - val_loss: 0.5907 - val_accuracy: 0.8421\n",
      "Epoch 92/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3764 - accuracy: 0.8600 - val_loss: 0.4932 - val_accuracy: 0.8421\n",
      "Epoch 93/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4009 - accuracy: 0.8600 - val_loss: 0.4880 - val_accuracy: 0.8289\n",
      "Epoch 94/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3885 - accuracy: 0.8500 - val_loss: 0.5096 - val_accuracy: 0.8289\n",
      "Epoch 95/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4391 - accuracy: 0.8433 - val_loss: 0.4804 - val_accuracy: 0.8289\n",
      "Epoch 96/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4280 - accuracy: 0.8167 - val_loss: 0.5405 - val_accuracy: 0.8289\n",
      "Epoch 97/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.4002 - accuracy: 0.8567 - val_loss: 0.4787 - val_accuracy: 0.8289\n",
      "Epoch 98/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3822 - accuracy: 0.8533 - val_loss: 0.5000 - val_accuracy: 0.8289\n",
      "Epoch 99/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.3871 - accuracy: 0.8500 - val_loss: 0.4862 - val_accuracy: 0.8289\n",
      "Epoch 100/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3681 - accuracy: 0.8500 - val_loss: 0.4828 - val_accuracy: 0.8289\n",
      "Epoch 101/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3720 - accuracy: 0.8500 - val_loss: 0.5120 - val_accuracy: 0.8289\n",
      "Epoch 102/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3695 - accuracy: 0.8500 - val_loss: 0.5629 - val_accuracy: 0.8289\n",
      "Epoch 103/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3763 - accuracy: 0.8500 - val_loss: 0.4891 - val_accuracy: 0.8289\n",
      "Epoch 104/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3976 - accuracy: 0.8633 - val_loss: 0.5090 - val_accuracy: 0.8289\n",
      "Epoch 105/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4220 - accuracy: 0.8333 - val_loss: 0.6008 - val_accuracy: 0.8289\n",
      "Epoch 106/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4011 - accuracy: 0.8567 - val_loss: 0.4836 - val_accuracy: 0.8421\n",
      "Epoch 107/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3872 - accuracy: 0.8567 - val_loss: 0.5341 - val_accuracy: 0.8289\n",
      "Epoch 108/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3911 - accuracy: 0.8500 - val_loss: 0.5824 - val_accuracy: 0.8289\n",
      "Epoch 109/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4281 - accuracy: 0.8433 - val_loss: 0.5167 - val_accuracy: 0.8026\n",
      "Epoch 110/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4048 - accuracy: 0.8500 - val_loss: 0.6148 - val_accuracy: 0.6711\n",
      "Epoch 111/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4473 - accuracy: 0.8267 - val_loss: 0.5318 - val_accuracy: 0.8289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.4132 - accuracy: 0.8467 - val_loss: 0.4899 - val_accuracy: 0.8289\n",
      "Epoch 113/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3896 - accuracy: 0.8433 - val_loss: 0.5294 - val_accuracy: 0.8289\n",
      "Epoch 114/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3749 - accuracy: 0.8500 - val_loss: 0.6085 - val_accuracy: 0.8289\n",
      "Epoch 115/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4388 - accuracy: 0.8367 - val_loss: 0.4925 - val_accuracy: 0.8289\n",
      "Epoch 116/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3950 - accuracy: 0.8600 - val_loss: 0.5068 - val_accuracy: 0.8158\n",
      "Epoch 117/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4070 - accuracy: 0.8333 - val_loss: 0.5344 - val_accuracy: 0.8289\n",
      "Epoch 118/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3779 - accuracy: 0.8433 - val_loss: 0.5176 - val_accuracy: 0.8289\n",
      "Epoch 119/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3690 - accuracy: 0.8600 - val_loss: 0.5218 - val_accuracy: 0.8289\n",
      "Epoch 120/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3879 - accuracy: 0.8500 - val_loss: 0.4864 - val_accuracy: 0.8289\n",
      "Epoch 121/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3845 - accuracy: 0.8500 - val_loss: 0.4969 - val_accuracy: 0.8289\n",
      "Epoch 122/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3866 - accuracy: 0.8533 - val_loss: 0.5192 - val_accuracy: 0.8158\n",
      "Epoch 123/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.3772 - accuracy: 0.8600 - val_loss: 0.5697 - val_accuracy: 0.8289\n",
      "Epoch 124/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3664 - accuracy: 0.8533 - val_loss: 0.4868 - val_accuracy: 0.8289\n",
      "Epoch 125/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3801 - accuracy: 0.8500 - val_loss: 0.5130 - val_accuracy: 0.8158\n",
      "Epoch 126/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3905 - accuracy: 0.8500 - val_loss: 0.5003 - val_accuracy: 0.8158\n",
      "Epoch 127/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4716 - accuracy: 0.8267 - val_loss: 0.5538 - val_accuracy: 0.8289\n",
      "Epoch 128/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4070 - accuracy: 0.8500 - val_loss: 0.5070 - val_accuracy: 0.8158\n",
      "Epoch 129/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3865 - accuracy: 0.8433 - val_loss: 0.5067 - val_accuracy: 0.8289\n",
      "Epoch 130/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3793 - accuracy: 0.8567 - val_loss: 0.5228 - val_accuracy: 0.8289\n",
      "Epoch 131/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3691 - accuracy: 0.8467 - val_loss: 0.5231 - val_accuracy: 0.8289\n",
      "Epoch 132/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3926 - accuracy: 0.8433 - val_loss: 0.4913 - val_accuracy: 0.8158\n",
      "Epoch 133/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4939 - accuracy: 0.8533 - val_loss: 0.7528 - val_accuracy: 0.8421\n",
      "Epoch 134/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4099 - accuracy: 0.8500 - val_loss: 0.5163 - val_accuracy: 0.8289\n",
      "Epoch 135/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3609 - accuracy: 0.8533 - val_loss: 0.5122 - val_accuracy: 0.8289\n",
      "Epoch 136/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3878 - accuracy: 0.8367 - val_loss: 0.5223 - val_accuracy: 0.7895\n",
      "Epoch 137/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4437 - accuracy: 0.8367 - val_loss: 0.5632 - val_accuracy: 0.8158\n",
      "Epoch 138/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4000 - accuracy: 0.8467 - val_loss: 0.6044 - val_accuracy: 0.8158\n",
      "Epoch 139/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3891 - accuracy: 0.8500 - val_loss: 0.5612 - val_accuracy: 0.8026\n",
      "Epoch 140/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.3866 - accuracy: 0.8467 - val_loss: 0.5110 - val_accuracy: 0.8158\n",
      "Epoch 141/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3977 - accuracy: 0.8500 - val_loss: 0.7316 - val_accuracy: 0.8421\n",
      "Epoch 142/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.4077 - accuracy: 0.8400 - val_loss: 0.6085 - val_accuracy: 0.8289\n",
      "Epoch 143/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4077 - accuracy: 0.8500 - val_loss: 0.5289 - val_accuracy: 0.7895\n",
      "Epoch 144/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.4022 - accuracy: 0.8400 - val_loss: 0.5313 - val_accuracy: 0.8289\n",
      "Epoch 145/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4658 - accuracy: 0.8300 - val_loss: 0.6138 - val_accuracy: 0.8289\n",
      "Epoch 146/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4512 - accuracy: 0.8200 - val_loss: 0.6376 - val_accuracy: 0.8289\n",
      "Epoch 147/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4189 - accuracy: 0.8400 - val_loss: 0.5344 - val_accuracy: 0.7895\n",
      "Epoch 148/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4092 - accuracy: 0.8267 - val_loss: 0.8139 - val_accuracy: 0.8421\n",
      "Epoch 149/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3731 - accuracy: 0.8467 - val_loss: 0.5375 - val_accuracy: 0.8289\n",
      "Epoch 150/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3836 - accuracy: 0.8567 - val_loss: 0.5335 - val_accuracy: 0.8026\n",
      "Epoch 151/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3960 - accuracy: 0.8433 - val_loss: 0.6627 - val_accuracy: 0.8289\n",
      "Epoch 152/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3986 - accuracy: 0.8533 - val_loss: 0.5145 - val_accuracy: 0.8026\n",
      "Epoch 153/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4044 - accuracy: 0.8467 - val_loss: 0.5631 - val_accuracy: 0.7500\n",
      "Epoch 154/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.4457 - accuracy: 0.8233 - val_loss: 0.7020 - val_accuracy: 0.8421\n",
      "Epoch 155/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4138 - accuracy: 0.8533 - val_loss: 0.6387 - val_accuracy: 0.8289\n",
      "Epoch 156/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3833 - accuracy: 0.8467 - val_loss: 0.5100 - val_accuracy: 0.8158\n",
      "Epoch 157/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3800 - accuracy: 0.8567 - val_loss: 0.6460 - val_accuracy: 0.8289\n",
      "Epoch 158/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3677 - accuracy: 0.8600 - val_loss: 0.5203 - val_accuracy: 0.8158\n",
      "Epoch 159/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3616 - accuracy: 0.8500 - val_loss: 0.5468 - val_accuracy: 0.7895\n",
      "Epoch 160/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3948 - accuracy: 0.8567 - val_loss: 0.5223 - val_accuracy: 0.8026\n",
      "Epoch 161/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3829 - accuracy: 0.8500 - val_loss: 0.5402 - val_accuracy: 0.8289\n",
      "Epoch 162/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4027 - accuracy: 0.8467 - val_loss: 0.5153 - val_accuracy: 0.8158\n",
      "Epoch 163/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3567 - accuracy: 0.8367 - val_loss: 0.5386 - val_accuracy: 0.8289\n",
      "Epoch 164/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3672 - accuracy: 0.8600 - val_loss: 0.5055 - val_accuracy: 0.8421\n",
      "Epoch 165/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4159 - accuracy: 0.8367 - val_loss: 0.5337 - val_accuracy: 0.7895\n",
      "Epoch 166/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4610 - accuracy: 0.8333 - val_loss: 0.6002 - val_accuracy: 0.8289\n",
      "Epoch 167/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4352 - accuracy: 0.8400 - val_loss: 0.5435 - val_accuracy: 0.7632\n",
      "Epoch 168/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.4128 - accuracy: 0.8367 - val_loss: 0.5019 - val_accuracy: 0.8158\n",
      "Epoch 169/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3668 - accuracy: 0.8500 - val_loss: 0.5201 - val_accuracy: 0.8158\n",
      "Epoch 170/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3809 - accuracy: 0.8533 - val_loss: 0.4986 - val_accuracy: 0.8158\n",
      "Epoch 171/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3485 - accuracy: 0.8633 - val_loss: 0.5843 - val_accuracy: 0.7237\n",
      "Epoch 172/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4061 - accuracy: 0.8433 - val_loss: 0.5534 - val_accuracy: 0.8158\n",
      "Epoch 173/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3549 - accuracy: 0.8533 - val_loss: 0.5041 - val_accuracy: 0.8158\n",
      "Epoch 174/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3768 - accuracy: 0.8533 - val_loss: 0.5174 - val_accuracy: 0.8289\n",
      "Epoch 175/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3761 - accuracy: 0.8533 - val_loss: 0.5434 - val_accuracy: 0.8026\n",
      "Epoch 176/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4000 - accuracy: 0.8667 - val_loss: 0.4945 - val_accuracy: 0.8289\n",
      "Epoch 177/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3658 - accuracy: 0.8500 - val_loss: 0.5751 - val_accuracy: 0.8289\n",
      "Epoch 178/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3646 - accuracy: 0.8567 - val_loss: 0.5363 - val_accuracy: 0.8289\n",
      "Epoch 179/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3600 - accuracy: 0.8567 - val_loss: 0.5171 - val_accuracy: 0.8158\n",
      "Epoch 180/500\n",
      "300/300 [==============================] - 0s 90us/sample - loss: 0.4019 - accuracy: 0.8433 - val_loss: 0.5376 - val_accuracy: 0.8026\n",
      "Epoch 181/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3787 - accuracy: 0.8500 - val_loss: 0.6748 - val_accuracy: 0.8289\n",
      "Epoch 182/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4299 - accuracy: 0.8133 - val_loss: 0.5419 - val_accuracy: 0.7763\n",
      "Epoch 183/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3729 - accuracy: 0.8533 - val_loss: 0.5489 - val_accuracy: 0.8289\n",
      "Epoch 184/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4001 - accuracy: 0.8467 - val_loss: 0.5196 - val_accuracy: 0.7895\n",
      "Epoch 185/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3698 - accuracy: 0.8567 - val_loss: 0.6044 - val_accuracy: 0.8289\n",
      "Epoch 186/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3963 - accuracy: 0.8300 - val_loss: 0.5538 - val_accuracy: 0.7500\n",
      "Epoch 187/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4392 - accuracy: 0.8233 - val_loss: 0.5327 - val_accuracy: 0.8158\n",
      "Epoch 188/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3541 - accuracy: 0.8500 - val_loss: 0.6757 - val_accuracy: 0.8289\n",
      "Epoch 189/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4273 - accuracy: 0.8433 - val_loss: 0.5228 - val_accuracy: 0.7895\n",
      "Epoch 190/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3773 - accuracy: 0.8667 - val_loss: 0.5448 - val_accuracy: 0.8289\n",
      "Epoch 191/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3899 - accuracy: 0.8467 - val_loss: 0.6212 - val_accuracy: 0.8289\n",
      "Epoch 192/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4641 - accuracy: 0.8267 - val_loss: 0.5177 - val_accuracy: 0.8158\n",
      "Epoch 193/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4125 - accuracy: 0.8467 - val_loss: 0.5064 - val_accuracy: 0.8289\n",
      "Epoch 194/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3921 - accuracy: 0.8200 - val_loss: 0.7284 - val_accuracy: 0.8421\n",
      "Epoch 195/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3857 - accuracy: 0.8600 - val_loss: 0.5028 - val_accuracy: 0.8026\n",
      "Epoch 196/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3817 - accuracy: 0.8567 - val_loss: 0.5220 - val_accuracy: 0.8026\n",
      "Epoch 197/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3725 - accuracy: 0.8567 - val_loss: 0.5140 - val_accuracy: 0.8289\n",
      "Epoch 198/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4028 - accuracy: 0.8500 - val_loss: 0.5532 - val_accuracy: 0.8026\n",
      "Epoch 199/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3708 - accuracy: 0.8567 - val_loss: 0.5015 - val_accuracy: 0.8289\n",
      "Epoch 200/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3590 - accuracy: 0.8633 - val_loss: 0.6684 - val_accuracy: 0.8289\n",
      "Epoch 201/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4672 - accuracy: 0.8400 - val_loss: 0.6016 - val_accuracy: 0.7237\n",
      "Epoch 202/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4355 - accuracy: 0.8033 - val_loss: 0.5410 - val_accuracy: 0.8158\n",
      "Epoch 203/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4672 - accuracy: 0.8467 - val_loss: 0.5507 - val_accuracy: 0.8289\n",
      "Epoch 204/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3939 - accuracy: 0.8200 - val_loss: 0.5316 - val_accuracy: 0.8026\n",
      "Epoch 205/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3524 - accuracy: 0.8533 - val_loss: 0.5460 - val_accuracy: 0.8289\n",
      "Epoch 206/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3971 - accuracy: 0.8500 - val_loss: 0.5180 - val_accuracy: 0.8158\n",
      "Epoch 207/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3694 - accuracy: 0.8500 - val_loss: 0.5211 - val_accuracy: 0.8158\n",
      "Epoch 208/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3749 - accuracy: 0.8467 - val_loss: 0.5054 - val_accuracy: 0.8158\n",
      "Epoch 209/500\n",
      "300/300 [==============================] - 0s 91us/sample - loss: 0.3784 - accuracy: 0.8433 - val_loss: 0.5300 - val_accuracy: 0.8158\n",
      "Epoch 210/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.4281 - accuracy: 0.8200 - val_loss: 0.5111 - val_accuracy: 0.8026\n",
      "Epoch 211/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4614 - accuracy: 0.8233 - val_loss: 0.5106 - val_accuracy: 0.8158\n",
      "Epoch 212/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3706 - accuracy: 0.8633 - val_loss: 0.5016 - val_accuracy: 0.8289\n",
      "Epoch 213/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3746 - accuracy: 0.8533 - val_loss: 0.5289 - val_accuracy: 0.8026\n",
      "Epoch 214/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3894 - accuracy: 0.8433 - val_loss: 0.5735 - val_accuracy: 0.8158\n",
      "Epoch 215/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3698 - accuracy: 0.8600 - val_loss: 0.7378 - val_accuracy: 0.8421\n",
      "Epoch 216/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.4148 - accuracy: 0.8467 - val_loss: 0.5251 - val_accuracy: 0.7763\n",
      "Epoch 217/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3741 - accuracy: 0.8467 - val_loss: 0.5444 - val_accuracy: 0.8158\n",
      "Epoch 218/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3909 - accuracy: 0.8500 - val_loss: 0.5241 - val_accuracy: 0.8289\n",
      "Epoch 219/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.3709 - accuracy: 0.8333 - val_loss: 0.6781 - val_accuracy: 0.8289\n",
      "Epoch 220/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4157 - accuracy: 0.8267 - val_loss: 0.6221 - val_accuracy: 0.8289\n",
      "Epoch 221/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4032 - accuracy: 0.8333 - val_loss: 0.5863 - val_accuracy: 0.8289\n",
      "Epoch 222/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3717 - accuracy: 0.8400 - val_loss: 0.5321 - val_accuracy: 0.8158\n",
      "Epoch 223/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3576 - accuracy: 0.8567 - val_loss: 0.6300 - val_accuracy: 0.8289\n",
      "Epoch 224/500\n",
      "300/300 [==============================] - 0s 111us/sample - loss: 0.3959 - accuracy: 0.8500 - val_loss: 0.5201 - val_accuracy: 0.8289\n",
      "Epoch 225/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3523 - accuracy: 0.8567 - val_loss: 0.5325 - val_accuracy: 0.8289\n",
      "Epoch 226/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3614 - accuracy: 0.8433 - val_loss: 0.5209 - val_accuracy: 0.8289\n",
      "Epoch 227/500\n",
      "300/300 [==============================] - 0s 109us/sample - loss: 0.3599 - accuracy: 0.8533 - val_loss: 0.5156 - val_accuracy: 0.8158\n",
      "Epoch 228/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3812 - accuracy: 0.8633 - val_loss: 0.5557 - val_accuracy: 0.8289\n",
      "Epoch 229/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4030 - accuracy: 0.8100 - val_loss: 0.5366 - val_accuracy: 0.7763\n",
      "Epoch 230/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3798 - accuracy: 0.8467 - val_loss: 0.5251 - val_accuracy: 0.8289\n",
      "Epoch 231/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.4075 - accuracy: 0.8467 - val_loss: 0.6124 - val_accuracy: 0.8289\n",
      "Epoch 232/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3610 - accuracy: 0.8633 - val_loss: 0.5150 - val_accuracy: 0.8158\n",
      "Epoch 233/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3551 - accuracy: 0.8633 - val_loss: 0.5978 - val_accuracy: 0.8289\n",
      "Epoch 234/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3876 - accuracy: 0.8500 - val_loss: 0.5763 - val_accuracy: 0.7368\n",
      "Epoch 235/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3914 - accuracy: 0.8500 - val_loss: 0.5400 - val_accuracy: 0.7895\n",
      "Epoch 236/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4126 - accuracy: 0.8300 - val_loss: 0.8163 - val_accuracy: 0.8421\n",
      "Epoch 237/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.4587 - accuracy: 0.8600 - val_loss: 0.6684 - val_accuracy: 0.5921\n",
      "Epoch 238/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.4361 - accuracy: 0.8367 - val_loss: 0.7640 - val_accuracy: 0.8421\n",
      "Epoch 239/500\n",
      "300/300 [==============================] - 0s 86us/sample - loss: 0.4009 - accuracy: 0.8500 - val_loss: 0.5215 - val_accuracy: 0.8026\n",
      "Epoch 240/500\n",
      "300/300 [==============================] - 0s 88us/sample - loss: 0.3681 - accuracy: 0.8500 - val_loss: 0.5532 - val_accuracy: 0.8026\n",
      "Epoch 241/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3687 - accuracy: 0.8600 - val_loss: 0.5278 - val_accuracy: 0.8289\n",
      "Epoch 242/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3561 - accuracy: 0.8700 - val_loss: 0.5568 - val_accuracy: 0.8289\n",
      "Epoch 243/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3560 - accuracy: 0.8467 - val_loss: 0.5330 - val_accuracy: 0.8158\n",
      "Epoch 244/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3572 - accuracy: 0.8500 - val_loss: 0.5197 - val_accuracy: 0.8026\n",
      "Epoch 245/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.4084 - accuracy: 0.8333 - val_loss: 0.5553 - val_accuracy: 0.8158\n",
      "Epoch 246/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4037 - accuracy: 0.8467 - val_loss: 0.6789 - val_accuracy: 0.8289\n",
      "Epoch 247/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3969 - accuracy: 0.8533 - val_loss: 0.5318 - val_accuracy: 0.7763\n",
      "Epoch 248/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3932 - accuracy: 0.8333 - val_loss: 0.6136 - val_accuracy: 0.8158\n",
      "Epoch 249/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3682 - accuracy: 0.8533 - val_loss: 0.5339 - val_accuracy: 0.8289\n",
      "Epoch 250/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4113 - accuracy: 0.8500 - val_loss: 0.5876 - val_accuracy: 0.8158\n",
      "Epoch 251/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.4091 - accuracy: 0.8400 - val_loss: 0.5251 - val_accuracy: 0.8158\n",
      "Epoch 252/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3676 - accuracy: 0.8400 - val_loss: 0.5317 - val_accuracy: 0.8289\n",
      "Epoch 253/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4157 - accuracy: 0.8267 - val_loss: 0.5340 - val_accuracy: 0.7763\n",
      "Epoch 254/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3735 - accuracy: 0.8533 - val_loss: 0.5524 - val_accuracy: 0.8289\n",
      "Epoch 255/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3521 - accuracy: 0.8567 - val_loss: 0.5149 - val_accuracy: 0.8158\n",
      "Epoch 256/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3803 - accuracy: 0.8533 - val_loss: 0.5470 - val_accuracy: 0.7763\n",
      "Epoch 257/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3614 - accuracy: 0.8467 - val_loss: 0.6012 - val_accuracy: 0.8158\n",
      "Epoch 258/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3989 - accuracy: 0.8300 - val_loss: 0.7743 - val_accuracy: 0.8421\n",
      "Epoch 259/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3822 - accuracy: 0.8567 - val_loss: 0.5422 - val_accuracy: 0.8026\n",
      "Epoch 260/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3706 - accuracy: 0.8533 - val_loss: 0.5278 - val_accuracy: 0.7895\n",
      "Epoch 261/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4313 - accuracy: 0.8467 - val_loss: 0.5499 - val_accuracy: 0.8158\n",
      "Epoch 262/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3701 - accuracy: 0.8400 - val_loss: 0.6278 - val_accuracy: 0.8289\n",
      "Epoch 263/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3780 - accuracy: 0.8467 - val_loss: 0.5198 - val_accuracy: 0.8026\n",
      "Epoch 264/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3716 - accuracy: 0.8633 - val_loss: 0.5235 - val_accuracy: 0.8289\n",
      "Epoch 265/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3963 - accuracy: 0.8467 - val_loss: 0.6482 - val_accuracy: 0.8289\n",
      "Epoch 266/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3822 - accuracy: 0.8500 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 267/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3645 - accuracy: 0.8600 - val_loss: 0.5482 - val_accuracy: 0.8289\n",
      "Epoch 268/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3766 - accuracy: 0.8533 - val_loss: 0.5571 - val_accuracy: 0.7632\n",
      "Epoch 269/500\n",
      "300/300 [==============================] - 0s 92us/sample - loss: 0.3582 - accuracy: 0.8533 - val_loss: 0.6453 - val_accuracy: 0.8289\n",
      "Epoch 270/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4652 - accuracy: 0.8500 - val_loss: 0.5901 - val_accuracy: 0.8158\n",
      "Epoch 271/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4036 - accuracy: 0.8300 - val_loss: 0.5785 - val_accuracy: 0.7368\n",
      "Epoch 272/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4253 - accuracy: 0.8433 - val_loss: 0.5181 - val_accuracy: 0.8158\n",
      "Epoch 273/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3838 - accuracy: 0.8300 - val_loss: 0.5651 - val_accuracy: 0.8158\n",
      "Epoch 274/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3600 - accuracy: 0.8600 - val_loss: 0.5133 - val_accuracy: 0.8158\n",
      "Epoch 275/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3837 - accuracy: 0.8333 - val_loss: 0.5441 - val_accuracy: 0.8158\n",
      "Epoch 276/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3754 - accuracy: 0.8500 - val_loss: 0.5157 - val_accuracy: 0.8026\n",
      "Epoch 277/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3600 - accuracy: 0.8500 - val_loss: 0.5432 - val_accuracy: 0.7895\n",
      "Epoch 278/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3846 - accuracy: 0.8533 - val_loss: 0.5572 - val_accuracy: 0.8289\n",
      "Epoch 279/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3913 - accuracy: 0.8467 - val_loss: 0.5614 - val_accuracy: 0.7895\n",
      "Epoch 280/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3499 - accuracy: 0.8633 - val_loss: 0.5118 - val_accuracy: 0.8289\n",
      "Epoch 281/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3601 - accuracy: 0.8533 - val_loss: 0.5400 - val_accuracy: 0.8026\n",
      "Epoch 282/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3665 - accuracy: 0.8533 - val_loss: 0.5241 - val_accuracy: 0.7895\n",
      "Epoch 283/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3539 - accuracy: 0.8533 - val_loss: 0.5264 - val_accuracy: 0.7763\n",
      "Epoch 284/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3749 - accuracy: 0.8533 - val_loss: 0.5394 - val_accuracy: 0.8158\n",
      "Epoch 285/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3854 - accuracy: 0.8633 - val_loss: 0.5850 - val_accuracy: 0.8289\n",
      "Epoch 286/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.4664 - accuracy: 0.8267 - val_loss: 0.5887 - val_accuracy: 0.8289\n",
      "Epoch 287/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.4403 - accuracy: 0.8433 - val_loss: 0.5203 - val_accuracy: 0.8158\n",
      "Epoch 288/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3865 - accuracy: 0.8500 - val_loss: 0.5869 - val_accuracy: 0.8289\n",
      "Epoch 289/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3430 - accuracy: 0.8700 - val_loss: 0.5391 - val_accuracy: 0.8026\n",
      "Epoch 290/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3540 - accuracy: 0.8600 - val_loss: 0.5409 - val_accuracy: 0.8289\n",
      "Epoch 291/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.3688 - accuracy: 0.8633 - val_loss: 0.5151 - val_accuracy: 0.8289\n",
      "Epoch 292/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3923 - accuracy: 0.8400 - val_loss: 0.5212 - val_accuracy: 0.7895\n",
      "Epoch 293/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3855 - accuracy: 0.8533 - val_loss: 0.5695 - val_accuracy: 0.8158\n",
      "Epoch 294/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3711 - accuracy: 0.8567 - val_loss: 0.5285 - val_accuracy: 0.8026\n",
      "Epoch 295/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3458 - accuracy: 0.8567 - val_loss: 0.5213 - val_accuracy: 0.7895\n",
      "Epoch 296/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3663 - accuracy: 0.8633 - val_loss: 0.6122 - val_accuracy: 0.8289\n",
      "Epoch 297/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3759 - accuracy: 0.8433 - val_loss: 0.5510 - val_accuracy: 0.8289\n",
      "Epoch 298/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3689 - accuracy: 0.8500 - val_loss: 0.5731 - val_accuracy: 0.8289\n",
      "Epoch 299/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3874 - accuracy: 0.8500 - val_loss: 0.5804 - val_accuracy: 0.7895\n",
      "Epoch 300/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3775 - accuracy: 0.8467 - val_loss: 0.5146 - val_accuracy: 0.8289\n",
      "Epoch 301/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3798 - accuracy: 0.8267 - val_loss: 0.6599 - val_accuracy: 0.8289\n",
      "Epoch 302/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.4333 - accuracy: 0.8333 - val_loss: 0.6206 - val_accuracy: 0.8158\n",
      "Epoch 303/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.4018 - accuracy: 0.8200 - val_loss: 0.5756 - val_accuracy: 0.7368\n",
      "Epoch 304/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.4321 - accuracy: 0.8433 - val_loss: 0.6835 - val_accuracy: 0.8026\n",
      "Epoch 305/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3482 - accuracy: 0.8567 - val_loss: 0.5827 - val_accuracy: 0.8289\n",
      "Epoch 306/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3704 - accuracy: 0.8633 - val_loss: 0.5736 - val_accuracy: 0.8289\n",
      "Epoch 307/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.80 - 0s 103us/sample - loss: 0.3537 - accuracy: 0.8567 - val_loss: 0.5467 - val_accuracy: 0.8289\n",
      "Epoch 308/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3507 - accuracy: 0.8567 - val_loss: 0.5236 - val_accuracy: 0.7895\n",
      "Epoch 309/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3590 - accuracy: 0.8600 - val_loss: 0.5771 - val_accuracy: 0.8158\n",
      "Epoch 310/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3565 - accuracy: 0.8567 - val_loss: 0.5438 - val_accuracy: 0.7632\n",
      "Epoch 311/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3677 - accuracy: 0.8433 - val_loss: 0.5620 - val_accuracy: 0.8289\n",
      "Epoch 312/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3689 - accuracy: 0.8567 - val_loss: 0.5178 - val_accuracy: 0.8289\n",
      "Epoch 313/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3801 - accuracy: 0.8533 - val_loss: 0.7879 - val_accuracy: 0.8421\n",
      "Epoch 314/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.4208 - accuracy: 0.8400 - val_loss: 0.5199 - val_accuracy: 0.8026\n",
      "Epoch 315/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3550 - accuracy: 0.8567 - val_loss: 0.5899 - val_accuracy: 0.7895\n",
      "Epoch 316/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3645 - accuracy: 0.8567 - val_loss: 0.5482 - val_accuracy: 0.8289\n",
      "Epoch 317/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3747 - accuracy: 0.8600 - val_loss: 0.5899 - val_accuracy: 0.8289\n",
      "Epoch 318/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3652 - accuracy: 0.8433 - val_loss: 0.5402 - val_accuracy: 0.8289\n",
      "Epoch 319/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3498 - accuracy: 0.8567 - val_loss: 0.5961 - val_accuracy: 0.8289\n",
      "Epoch 320/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3905 - accuracy: 0.8433 - val_loss: 0.5206 - val_accuracy: 0.8158\n",
      "Epoch 321/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3558 - accuracy: 0.8567 - val_loss: 0.6380 - val_accuracy: 0.8289\n",
      "Epoch 322/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3761 - accuracy: 0.8567 - val_loss: 0.5742 - val_accuracy: 0.7368\n",
      "Epoch 323/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3774 - accuracy: 0.8533 - val_loss: 0.5290 - val_accuracy: 0.8289\n",
      "Epoch 324/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3964 - accuracy: 0.8467 - val_loss: 0.5534 - val_accuracy: 0.8026\n",
      "Epoch 325/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3790 - accuracy: 0.8567 - val_loss: 0.5910 - val_accuracy: 0.8158\n",
      "Epoch 326/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3541 - accuracy: 0.8567 - val_loss: 0.5239 - val_accuracy: 0.7895\n",
      "Epoch 327/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3587 - accuracy: 0.8600 - val_loss: 0.5262 - val_accuracy: 0.8026\n",
      "Epoch 328/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3776 - accuracy: 0.8400 - val_loss: 0.6117 - val_accuracy: 0.8158\n",
      "Epoch 329/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3883 - accuracy: 0.8633 - val_loss: 0.5344 - val_accuracy: 0.8158\n",
      "Epoch 330/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3818 - accuracy: 0.8533 - val_loss: 0.5387 - val_accuracy: 0.7632\n",
      "Epoch 331/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3477 - accuracy: 0.8667 - val_loss: 0.6098 - val_accuracy: 0.8289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3631 - accuracy: 0.8633 - val_loss: 0.5541 - val_accuracy: 0.7895\n",
      "Epoch 333/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3521 - accuracy: 0.8633 - val_loss: 0.5453 - val_accuracy: 0.7895\n",
      "Epoch 334/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4206 - accuracy: 0.8633 - val_loss: 0.6764 - val_accuracy: 0.8289\n",
      "Epoch 335/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3621 - accuracy: 0.8500 - val_loss: 0.5202 - val_accuracy: 0.8289\n",
      "Epoch 336/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3500 - accuracy: 0.8500 - val_loss: 0.5746 - val_accuracy: 0.8026\n",
      "Epoch 337/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3448 - accuracy: 0.8700 - val_loss: 0.5517 - val_accuracy: 0.7368\n",
      "Epoch 338/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3644 - accuracy: 0.8600 - val_loss: 0.5539 - val_accuracy: 0.8289\n",
      "Epoch 339/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3856 - accuracy: 0.8633 - val_loss: 0.5203 - val_accuracy: 0.7500\n",
      "Epoch 340/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3998 - accuracy: 0.8500 - val_loss: 0.5882 - val_accuracy: 0.8158\n",
      "Epoch 341/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3725 - accuracy: 0.8567 - val_loss: 0.6871 - val_accuracy: 0.8289\n",
      "Epoch 342/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.4112 - accuracy: 0.8400 - val_loss: 0.7350 - val_accuracy: 0.8289\n",
      "Epoch 343/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3663 - accuracy: 0.8533 - val_loss: 0.5393 - val_accuracy: 0.7895\n",
      "Epoch 344/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3607 - accuracy: 0.8500 - val_loss: 0.5742 - val_accuracy: 0.8289\n",
      "Epoch 345/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3620 - accuracy: 0.8633 - val_loss: 0.6145 - val_accuracy: 0.7895\n",
      "Epoch 346/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3828 - accuracy: 0.8533 - val_loss: 0.5520 - val_accuracy: 0.8289\n",
      "Epoch 347/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4433 - accuracy: 0.8467 - val_loss: 0.5605 - val_accuracy: 0.7895\n",
      "Epoch 348/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.3771 - accuracy: 0.8367 - val_loss: 0.5380 - val_accuracy: 0.8289\n",
      "Epoch 349/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3539 - accuracy: 0.8567 - val_loss: 0.5661 - val_accuracy: 0.8289\n",
      "Epoch 350/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3360 - accuracy: 0.8500 - val_loss: 0.6043 - val_accuracy: 0.6842\n",
      "Epoch 351/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3990 - accuracy: 0.8500 - val_loss: 0.5302 - val_accuracy: 0.7895\n",
      "Epoch 352/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3715 - accuracy: 0.8533 - val_loss: 0.5138 - val_accuracy: 0.8026\n",
      "Epoch 353/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3531 - accuracy: 0.8567 - val_loss: 0.5358 - val_accuracy: 0.7632\n",
      "Epoch 354/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3392 - accuracy: 0.8633 - val_loss: 0.5539 - val_accuracy: 0.7500\n",
      "Epoch 355/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3493 - accuracy: 0.8567 - val_loss: 0.5790 - val_accuracy: 0.8158\n",
      "Epoch 356/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3613 - accuracy: 0.8300 - val_loss: 0.5543 - val_accuracy: 0.7763\n",
      "Epoch 357/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3870 - accuracy: 0.8567 - val_loss: 0.5431 - val_accuracy: 0.7763\n",
      "Epoch 358/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3574 - accuracy: 0.8500 - val_loss: 0.5472 - val_accuracy: 0.8289\n",
      "Epoch 359/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3801 - accuracy: 0.8467 - val_loss: 0.5652 - val_accuracy: 0.8289\n",
      "Epoch 360/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3650 - accuracy: 0.8467 - val_loss: 0.6194 - val_accuracy: 0.8289\n",
      "Epoch 361/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3866 - accuracy: 0.8600 - val_loss: 0.5569 - val_accuracy: 0.8026\n",
      "Epoch 362/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3487 - accuracy: 0.8533 - val_loss: 0.5623 - val_accuracy: 0.8289\n",
      "Epoch 363/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3748 - accuracy: 0.8600 - val_loss: 0.5304 - val_accuracy: 0.8289\n",
      "Epoch 364/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3520 - accuracy: 0.8567 - val_loss: 0.5233 - val_accuracy: 0.8026\n",
      "Epoch 365/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3635 - accuracy: 0.8700 - val_loss: 0.5307 - val_accuracy: 0.7895\n",
      "Epoch 366/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3720 - accuracy: 0.8467 - val_loss: 0.5920 - val_accuracy: 0.8289\n",
      "Epoch 367/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3838 - accuracy: 0.8533 - val_loss: 0.6033 - val_accuracy: 0.8289\n",
      "Epoch 368/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3499 - accuracy: 0.8600 - val_loss: 0.7358 - val_accuracy: 0.8289\n",
      "Epoch 369/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3964 - accuracy: 0.8400 - val_loss: 0.5413 - val_accuracy: 0.8026\n",
      "Epoch 370/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3560 - accuracy: 0.8567 - val_loss: 0.5292 - val_accuracy: 0.7895\n",
      "Epoch 371/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3332 - accuracy: 0.8600 - val_loss: 0.5368 - val_accuracy: 0.8026\n",
      "Epoch 372/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4098 - accuracy: 0.8333 - val_loss: 0.6662 - val_accuracy: 0.8289\n",
      "Epoch 373/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.4039 - accuracy: 0.8400 - val_loss: 0.5112 - val_accuracy: 0.8026\n",
      "Epoch 374/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.3458 - accuracy: 0.8567 - val_loss: 0.5490 - val_accuracy: 0.7632\n",
      "Epoch 375/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3586 - accuracy: 0.8633 - val_loss: 0.5422 - val_accuracy: 0.8026\n",
      "Epoch 376/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3498 - accuracy: 0.8567 - val_loss: 0.5380 - val_accuracy: 0.8289\n",
      "Epoch 377/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3459 - accuracy: 0.8467 - val_loss: 0.5504 - val_accuracy: 0.7500\n",
      "Epoch 378/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3886 - accuracy: 0.8467 - val_loss: 0.5378 - val_accuracy: 0.8026\n",
      "Epoch 379/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3688 - accuracy: 0.8533 - val_loss: 0.5294 - val_accuracy: 0.8289\n",
      "Epoch 380/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3552 - accuracy: 0.8600 - val_loss: 0.5079 - val_accuracy: 0.8026\n",
      "Epoch 381/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3397 - accuracy: 0.8500 - val_loss: 0.5867 - val_accuracy: 0.8289\n",
      "Epoch 382/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3337 - accuracy: 0.8600 - val_loss: 0.6006 - val_accuracy: 0.8289\n",
      "Epoch 383/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3985 - accuracy: 0.8467 - val_loss: 0.6060 - val_accuracy: 0.7237\n",
      "Epoch 384/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3640 - accuracy: 0.8500 - val_loss: 0.5353 - val_accuracy: 0.8026\n",
      "Epoch 385/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3512 - accuracy: 0.8633 - val_loss: 0.5569 - val_accuracy: 0.8026\n",
      "Epoch 386/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3488 - accuracy: 0.8600 - val_loss: 0.5572 - val_accuracy: 0.8289\n",
      "Epoch 387/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3456 - accuracy: 0.8733 - val_loss: 0.5432 - val_accuracy: 0.8026\n",
      "Epoch 388/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3728 - accuracy: 0.8467 - val_loss: 0.7022 - val_accuracy: 0.8289\n",
      "Epoch 389/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3810 - accuracy: 0.8467 - val_loss: 0.5730 - val_accuracy: 0.8289\n",
      "Epoch 390/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3412 - accuracy: 0.8533 - val_loss: 0.5759 - val_accuracy: 0.8289\n",
      "Epoch 391/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.4143 - accuracy: 0.8500 - val_loss: 0.5986 - val_accuracy: 0.7500\n",
      "Epoch 392/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3843 - accuracy: 0.8633 - val_loss: 0.5870 - val_accuracy: 0.8026\n",
      "Epoch 393/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3698 - accuracy: 0.8533 - val_loss: 0.5370 - val_accuracy: 0.8289\n",
      "Epoch 394/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3614 - accuracy: 0.8567 - val_loss: 0.5528 - val_accuracy: 0.7632\n",
      "Epoch 395/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3969 - accuracy: 0.8467 - val_loss: 0.5362 - val_accuracy: 0.8026\n",
      "Epoch 396/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3549 - accuracy: 0.8667 - val_loss: 0.5596 - val_accuracy: 0.8289\n",
      "Epoch 397/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3526 - accuracy: 0.8600 - val_loss: 0.5353 - val_accuracy: 0.7763\n",
      "Epoch 398/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3714 - accuracy: 0.8400 - val_loss: 0.6371 - val_accuracy: 0.6579\n",
      "Epoch 399/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3771 - accuracy: 0.8467 - val_loss: 0.5241 - val_accuracy: 0.8158\n",
      "Epoch 400/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3542 - accuracy: 0.8533 - val_loss: 0.5299 - val_accuracy: 0.8158\n",
      "Epoch 401/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3529 - accuracy: 0.8567 - val_loss: 0.5842 - val_accuracy: 0.7368\n",
      "Epoch 402/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3777 - accuracy: 0.8567 - val_loss: 0.5507 - val_accuracy: 0.8289\n",
      "Epoch 403/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3807 - accuracy: 0.8600 - val_loss: 0.5959 - val_accuracy: 0.7895\n",
      "Epoch 404/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3397 - accuracy: 0.8700 - val_loss: 0.5087 - val_accuracy: 0.7895\n",
      "Epoch 405/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3347 - accuracy: 0.8667 - val_loss: 0.5723 - val_accuracy: 0.8289\n",
      "Epoch 406/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3686 - accuracy: 0.8467 - val_loss: 0.5698 - val_accuracy: 0.7763\n",
      "Epoch 407/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3845 - accuracy: 0.8333 - val_loss: 0.5894 - val_accuracy: 0.8026\n",
      "Epoch 408/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3944 - accuracy: 0.8467 - val_loss: 0.5825 - val_accuracy: 0.7237\n",
      "Epoch 409/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4329 - accuracy: 0.8333 - val_loss: 0.5616 - val_accuracy: 0.8158\n",
      "Epoch 410/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.4318 - accuracy: 0.8033 - val_loss: 0.7873 - val_accuracy: 0.8421\n",
      "Epoch 411/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.4182 - accuracy: 0.8633 - val_loss: 0.5955 - val_accuracy: 0.8289\n",
      "Epoch 412/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3574 - accuracy: 0.8600 - val_loss: 0.5178 - val_accuracy: 0.7895\n",
      "Epoch 413/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3626 - accuracy: 0.8567 - val_loss: 0.5048 - val_accuracy: 0.8158\n",
      "Epoch 414/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3471 - accuracy: 0.8467 - val_loss: 0.5825 - val_accuracy: 0.8289\n",
      "Epoch 415/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3646 - accuracy: 0.8433 - val_loss: 0.5357 - val_accuracy: 0.8289\n",
      "Epoch 416/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3615 - accuracy: 0.8500 - val_loss: 0.5580 - val_accuracy: 0.8026\n",
      "Epoch 417/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3847 - accuracy: 0.8367 - val_loss: 0.6107 - val_accuracy: 0.7368\n",
      "Epoch 418/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3454 - accuracy: 0.8633 - val_loss: 0.5456 - val_accuracy: 0.8289\n",
      "Epoch 419/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3499 - accuracy: 0.8600 - val_loss: 0.5471 - val_accuracy: 0.8158\n",
      "Epoch 420/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3436 - accuracy: 0.8633 - val_loss: 0.5675 - val_accuracy: 0.8289\n",
      "Epoch 421/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3309 - accuracy: 0.8600 - val_loss: 0.5367 - val_accuracy: 0.8289\n",
      "Epoch 422/500\n",
      "300/300 [==============================] - 0s 108us/sample - loss: 0.3486 - accuracy: 0.8533 - val_loss: 0.5634 - val_accuracy: 0.8289\n",
      "Epoch 423/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3722 - accuracy: 0.8733 - val_loss: 0.5848 - val_accuracy: 0.8289\n",
      "Epoch 424/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.3544 - accuracy: 0.8633 - val_loss: 0.6074 - val_accuracy: 0.8158\n",
      "Epoch 425/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3511 - accuracy: 0.8567 - val_loss: 0.6782 - val_accuracy: 0.8289\n",
      "Epoch 426/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.4620 - accuracy: 0.8500 - val_loss: 0.5676 - val_accuracy: 0.7895\n",
      "Epoch 427/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3653 - accuracy: 0.8500 - val_loss: 0.7254 - val_accuracy: 0.8289\n",
      "Epoch 428/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3735 - accuracy: 0.8567 - val_loss: 0.5226 - val_accuracy: 0.7895\n",
      "Epoch 429/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3416 - accuracy: 0.8567 - val_loss: 0.6221 - val_accuracy: 0.8158\n",
      "Epoch 430/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3660 - accuracy: 0.8467 - val_loss: 0.5606 - val_accuracy: 0.8289\n",
      "Epoch 431/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3528 - accuracy: 0.8633 - val_loss: 0.5647 - val_accuracy: 0.8026\n",
      "Epoch 432/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3711 - accuracy: 0.8667 - val_loss: 0.5519 - val_accuracy: 0.8026\n",
      "Epoch 433/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3720 - accuracy: 0.8633 - val_loss: 0.5156 - val_accuracy: 0.8026\n",
      "Epoch 434/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3759 - accuracy: 0.8700 - val_loss: 0.6002 - val_accuracy: 0.8026\n",
      "Epoch 435/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3481 - accuracy: 0.8733 - val_loss: 0.5233 - val_accuracy: 0.8289\n",
      "Epoch 436/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3413 - accuracy: 0.8533 - val_loss: 0.6645 - val_accuracy: 0.8026\n",
      "Epoch 437/500\n",
      "300/300 [==============================] - 0s 95us/sample - loss: 0.3395 - accuracy: 0.8533 - val_loss: 0.5465 - val_accuracy: 0.8289\n",
      "Epoch 438/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3387 - accuracy: 0.8467 - val_loss: 0.5869 - val_accuracy: 0.8289\n",
      "Epoch 439/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3497 - accuracy: 0.8633 - val_loss: 0.5162 - val_accuracy: 0.8026\n",
      "Epoch 440/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.3646 - accuracy: 0.8700 - val_loss: 0.5645 - val_accuracy: 0.8289\n",
      "Epoch 441/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3672 - accuracy: 0.8433 - val_loss: 0.5276 - val_accuracy: 0.7763\n",
      "Epoch 442/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3511 - accuracy: 0.8667 - val_loss: 0.6629 - val_accuracy: 0.8289\n",
      "Epoch 443/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3903 - accuracy: 0.8400 - val_loss: 0.5783 - val_accuracy: 0.7500\n",
      "Epoch 444/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3851 - accuracy: 0.8633 - val_loss: 0.5061 - val_accuracy: 0.8026\n",
      "Epoch 445/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3353 - accuracy: 0.8767 - val_loss: 0.5333 - val_accuracy: 0.7895\n",
      "Epoch 446/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3422 - accuracy: 0.8600 - val_loss: 0.6817 - val_accuracy: 0.8289\n",
      "Epoch 447/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.4269 - accuracy: 0.8267 - val_loss: 0.6236 - val_accuracy: 0.7368\n",
      "Epoch 448/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3726 - accuracy: 0.8367 - val_loss: 0.7277 - val_accuracy: 0.8289\n",
      "Epoch 449/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3983 - accuracy: 0.8633 - val_loss: 0.5484 - val_accuracy: 0.7763\n",
      "Epoch 450/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3517 - accuracy: 0.8567 - val_loss: 0.5433 - val_accuracy: 0.8026\n",
      "Epoch 451/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3497 - accuracy: 0.8700 - val_loss: 0.6100 - val_accuracy: 0.8158\n",
      "Epoch 452/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3406 - accuracy: 0.8733 - val_loss: 0.5435 - val_accuracy: 0.8026\n",
      "Epoch 453/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4125 - accuracy: 0.8633 - val_loss: 0.5609 - val_accuracy: 0.8158\n",
      "Epoch 454/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3465 - accuracy: 0.8567 - val_loss: 0.5316 - val_accuracy: 0.8289\n",
      "Epoch 455/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3789 - accuracy: 0.8633 - val_loss: 0.6201 - val_accuracy: 0.7237\n",
      "Epoch 456/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3577 - accuracy: 0.8500 - val_loss: 0.5328 - val_accuracy: 0.8289\n",
      "Epoch 457/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3355 - accuracy: 0.8733 - val_loss: 0.5735 - val_accuracy: 0.8289\n",
      "Epoch 458/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3539 - accuracy: 0.8433 - val_loss: 0.5490 - val_accuracy: 0.7632\n",
      "Epoch 459/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3332 - accuracy: 0.8700 - val_loss: 0.5142 - val_accuracy: 0.8026\n",
      "Epoch 460/500\n",
      "300/300 [==============================] - 0s 104us/sample - loss: 0.3462 - accuracy: 0.8733 - val_loss: 0.5167 - val_accuracy: 0.7895\n",
      "Epoch 461/500\n",
      "300/300 [==============================] - 0s 105us/sample - loss: 0.3319 - accuracy: 0.8667 - val_loss: 0.6160 - val_accuracy: 0.8289\n",
      "Epoch 462/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3812 - accuracy: 0.8733 - val_loss: 0.5599 - val_accuracy: 0.8026\n",
      "Epoch 463/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.80 - 0s 97us/sample - loss: 0.3600 - accuracy: 0.8367 - val_loss: 0.7210 - val_accuracy: 0.8158\n",
      "Epoch 464/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.7194 - accuracy: 0.80 - 0s 102us/sample - loss: 0.4503 - accuracy: 0.8200 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
      "Epoch 465/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3403 - accuracy: 0.8733 - val_loss: 0.5630 - val_accuracy: 0.8289\n",
      "Epoch 466/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3559 - accuracy: 0.8567 - val_loss: 0.6021 - val_accuracy: 0.7237\n",
      "Epoch 467/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.4253 - accuracy: 0.8467 - val_loss: 0.6864 - val_accuracy: 0.8289\n",
      "Epoch 468/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3404 - accuracy: 0.8567 - val_loss: 0.5215 - val_accuracy: 0.7895\n",
      "Epoch 469/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3431 - accuracy: 0.8567 - val_loss: 0.5580 - val_accuracy: 0.8158\n",
      "Epoch 470/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3426 - accuracy: 0.8633 - val_loss: 0.5848 - val_accuracy: 0.7368\n",
      "Epoch 471/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3692 - accuracy: 0.8567 - val_loss: 0.5589 - val_accuracy: 0.8158\n",
      "Epoch 472/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3520 - accuracy: 0.8733 - val_loss: 0.5517 - val_accuracy: 0.8289\n",
      "Epoch 473/500\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.6362 - accuracy: 0.70 - 0s 96us/sample - loss: 0.3484 - accuracy: 0.8567 - val_loss: 0.5139 - val_accuracy: 0.8026\n",
      "Epoch 474/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3460 - accuracy: 0.8667 - val_loss: 0.5040 - val_accuracy: 0.8026\n",
      "Epoch 475/500\n",
      "300/300 [==============================] - 0s 101us/sample - loss: 0.3617 - accuracy: 0.8567 - val_loss: 0.5139 - val_accuracy: 0.8026\n",
      "Epoch 476/500\n",
      "300/300 [==============================] - 0s 102us/sample - loss: 0.3299 - accuracy: 0.8700 - val_loss: 0.5305 - val_accuracy: 0.8026\n",
      "Epoch 477/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4074 - accuracy: 0.8533 - val_loss: 0.5981 - val_accuracy: 0.8289\n",
      "Epoch 478/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3859 - accuracy: 0.8367 - val_loss: 0.5540 - val_accuracy: 0.8289\n",
      "Epoch 479/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3506 - accuracy: 0.8533 - val_loss: 0.5284 - val_accuracy: 0.8158\n",
      "Epoch 480/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3375 - accuracy: 0.8633 - val_loss: 0.5282 - val_accuracy: 0.8158\n",
      "Epoch 481/500\n",
      "300/300 [==============================] - 0s 107us/sample - loss: 0.3333 - accuracy: 0.8567 - val_loss: 0.5472 - val_accuracy: 0.8158\n",
      "Epoch 482/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3336 - accuracy: 0.8767 - val_loss: 0.5219 - val_accuracy: 0.8026\n",
      "Epoch 483/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3206 - accuracy: 0.8800 - val_loss: 0.5261 - val_accuracy: 0.7895\n",
      "Epoch 484/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.3379 - accuracy: 0.8600 - val_loss: 0.6041 - val_accuracy: 0.8289\n",
      "Epoch 485/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3518 - accuracy: 0.8633 - val_loss: 0.5737 - val_accuracy: 0.8289\n",
      "Epoch 486/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3269 - accuracy: 0.8633 - val_loss: 0.6702 - val_accuracy: 0.8158\n",
      "Epoch 487/500\n",
      "300/300 [==============================] - 0s 97us/sample - loss: 0.3278 - accuracy: 0.8700 - val_loss: 0.5148 - val_accuracy: 0.8026\n",
      "Epoch 488/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3552 - accuracy: 0.8700 - val_loss: 0.5358 - val_accuracy: 0.7895\n",
      "Epoch 489/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3649 - accuracy: 0.8633 - val_loss: 0.6550 - val_accuracy: 0.8289\n",
      "Epoch 490/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.4023 - accuracy: 0.8733 - val_loss: 0.6168 - val_accuracy: 0.7105\n",
      "Epoch 491/500\n",
      "300/300 [==============================] - 0s 96us/sample - loss: 0.3751 - accuracy: 0.8567 - val_loss: 0.5379 - val_accuracy: 0.8158\n",
      "Epoch 492/500\n",
      "300/300 [==============================] - 0s 103us/sample - loss: 0.4037 - accuracy: 0.8533 - val_loss: 0.5408 - val_accuracy: 0.8289\n",
      "Epoch 493/500\n",
      "300/300 [==============================] - 0s 98us/sample - loss: 0.3310 - accuracy: 0.8767 - val_loss: 0.5690 - val_accuracy: 0.8026\n",
      "Epoch 494/500\n",
      "300/300 [==============================] - 0s 94us/sample - loss: 0.3455 - accuracy: 0.8633 - val_loss: 0.5558 - val_accuracy: 0.8158\n",
      "Epoch 495/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3313 - accuracy: 0.8667 - val_loss: 0.5044 - val_accuracy: 0.8026\n",
      "Epoch 496/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3596 - accuracy: 0.8633 - val_loss: 0.5871 - val_accuracy: 0.8158\n",
      "Epoch 497/500\n",
      "300/300 [==============================] - 0s 93us/sample - loss: 0.3537 - accuracy: 0.8700 - val_loss: 0.6334 - val_accuracy: 0.8289\n",
      "Epoch 498/500\n",
      "300/300 [==============================] - 0s 106us/sample - loss: 0.3463 - accuracy: 0.8433 - val_loss: 0.5579 - val_accuracy: 0.8289\n",
      "Epoch 499/500\n",
      "300/300 [==============================] - 0s 99us/sample - loss: 0.3693 - accuracy: 0.8533 - val_loss: 0.6106 - val_accuracy: 0.8289\n",
      "Epoch 500/500\n",
      "300/300 [==============================] - 0s 100us/sample - loss: 0.3246 - accuracy: 0.8700 - val_loss: 0.6757 - val_accuracy: 0.8289\n"
     ]
    }
   ],
   "source": [
    "# 딥러닝 실행\n",
    "# Validation set의 비율을 20%\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=500, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 0s - loss: 0.7351 - accuracy: 0.8511\n",
      "\n",
      " Accuracy : 0.8511\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "# evaluate() returns the loss value & metrics values for the model\n",
    "print(\"\\n Accuracy : %.4f\"%(model.evaluate(X_test,Y_test,verbose=2))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5566667,\n",
       " 0.83,\n",
       " 0.7866667,\n",
       " 0.7733333,\n",
       " 0.80333334,\n",
       " 0.81333333,\n",
       " 0.81333333,\n",
       " 0.83,\n",
       " 0.83,\n",
       " 0.8233333,\n",
       " 0.84,\n",
       " 0.8466667,\n",
       " 0.84,\n",
       " 0.83666664,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.8466667,\n",
       " 0.8433333,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.8233333,\n",
       " 0.84,\n",
       " 0.8333333,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.86,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.86,\n",
       " 0.86,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.86,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.8433333,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.8433333,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.8433333,\n",
       " 0.85333335,\n",
       " 0.8566667,\n",
       " 0.84,\n",
       " 0.86,\n",
       " 0.86333334,\n",
       " 0.85,\n",
       " 0.8466667,\n",
       " 0.85333335,\n",
       " 0.82,\n",
       " 0.86,\n",
       " 0.85,\n",
       " 0.8433333,\n",
       " 0.8233333,\n",
       " 0.83666664,\n",
       " 0.8433333,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.84,\n",
       " 0.83666664,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.82666665,\n",
       " 0.85,\n",
       " 0.83666664,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.84,\n",
       " 0.86,\n",
       " 0.86,\n",
       " 0.85,\n",
       " 0.8433333,\n",
       " 0.81666666,\n",
       " 0.8566667,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.86333334,\n",
       " 0.8333333,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.8433333,\n",
       " 0.85,\n",
       " 0.82666665,\n",
       " 0.8466667,\n",
       " 0.8433333,\n",
       " 0.85,\n",
       " 0.83666664,\n",
       " 0.86,\n",
       " 0.8333333,\n",
       " 0.8433333,\n",
       " 0.86,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.86,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.82666665,\n",
       " 0.85,\n",
       " 0.8433333,\n",
       " 0.8566667,\n",
       " 0.8466667,\n",
       " 0.8433333,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.83666664,\n",
       " 0.83666664,\n",
       " 0.8466667,\n",
       " 0.85,\n",
       " 0.8466667,\n",
       " 0.85,\n",
       " 0.84,\n",
       " 0.85,\n",
       " 0.84,\n",
       " 0.83,\n",
       " 0.82,\n",
       " 0.84,\n",
       " 0.82666665,\n",
       " 0.8466667,\n",
       " 0.8566667,\n",
       " 0.8433333,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.8233333,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.8566667,\n",
       " 0.86,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.8466667,\n",
       " 0.83666664,\n",
       " 0.86,\n",
       " 0.83666664,\n",
       " 0.8333333,\n",
       " 0.84,\n",
       " 0.83666664,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.86333334,\n",
       " 0.8433333,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.8666667,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.8433333,\n",
       " 0.85,\n",
       " 0.81333333,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.8566667,\n",
       " 0.83,\n",
       " 0.8233333,\n",
       " 0.85,\n",
       " 0.8433333,\n",
       " 0.8666667,\n",
       " 0.8466667,\n",
       " 0.82666665,\n",
       " 0.8466667,\n",
       " 0.82,\n",
       " 0.86,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.84,\n",
       " 0.80333334,\n",
       " 0.8466667,\n",
       " 0.82,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.8466667,\n",
       " 0.8433333,\n",
       " 0.82,\n",
       " 0.8233333,\n",
       " 0.86333334,\n",
       " 0.85333335,\n",
       " 0.8433333,\n",
       " 0.86,\n",
       " 0.8466667,\n",
       " 0.8466667,\n",
       " 0.85,\n",
       " 0.8333333,\n",
       " 0.82666665,\n",
       " 0.8333333,\n",
       " 0.84,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.8433333,\n",
       " 0.85333335,\n",
       " 0.86333334,\n",
       " 0.81,\n",
       " 0.8466667,\n",
       " 0.8466667,\n",
       " 0.86333334,\n",
       " 0.86333334,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.83,\n",
       " 0.86,\n",
       " 0.83666664,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.86,\n",
       " 0.87,\n",
       " 0.8466667,\n",
       " 0.85,\n",
       " 0.8333333,\n",
       " 0.8466667,\n",
       " 0.85333335,\n",
       " 0.8333333,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.84,\n",
       " 0.84,\n",
       " 0.82666665,\n",
       " 0.85333335,\n",
       " 0.8566667,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.83,\n",
       " 0.8566667,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.84,\n",
       " 0.8466667,\n",
       " 0.86333334,\n",
       " 0.8466667,\n",
       " 0.85,\n",
       " 0.86,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.83,\n",
       " 0.8433333,\n",
       " 0.83,\n",
       " 0.86,\n",
       " 0.8333333,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.86333334,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.86333334,\n",
       " 0.82666665,\n",
       " 0.8433333,\n",
       " 0.85,\n",
       " 0.87,\n",
       " 0.86,\n",
       " 0.86333334,\n",
       " 0.84,\n",
       " 0.85333335,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.8433333,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.8466667,\n",
       " 0.82666665,\n",
       " 0.8333333,\n",
       " 0.82,\n",
       " 0.8433333,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.86,\n",
       " 0.8566667,\n",
       " 0.8433333,\n",
       " 0.8566667,\n",
       " 0.85333335,\n",
       " 0.84,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.86,\n",
       " 0.8433333,\n",
       " 0.8566667,\n",
       " 0.8433333,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.86,\n",
       " 0.84,\n",
       " 0.86333334,\n",
       " 0.85333335,\n",
       " 0.8666667,\n",
       " 0.86333334,\n",
       " 0.86333334,\n",
       " 0.86333334,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.87,\n",
       " 0.86,\n",
       " 0.86333334,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.84,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.86333334,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.83666664,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.85333335,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.83,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.8466667,\n",
       " 0.8466667,\n",
       " 0.86,\n",
       " 0.85333335,\n",
       " 0.86,\n",
       " 0.8566667,\n",
       " 0.87,\n",
       " 0.8466667,\n",
       " 0.85333335,\n",
       " 0.86,\n",
       " 0.84,\n",
       " 0.8566667,\n",
       " 0.86,\n",
       " 0.8333333,\n",
       " 0.84,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.8466667,\n",
       " 0.8466667,\n",
       " 0.85333335,\n",
       " 0.86,\n",
       " 0.85,\n",
       " 0.86,\n",
       " 0.8466667,\n",
       " 0.85,\n",
       " 0.86333334,\n",
       " 0.86,\n",
       " 0.87333333,\n",
       " 0.8466667,\n",
       " 0.8466667,\n",
       " 0.85333335,\n",
       " 0.85,\n",
       " 0.86333334,\n",
       " 0.85333335,\n",
       " 0.8566667,\n",
       " 0.8466667,\n",
       " 0.8666667,\n",
       " 0.86,\n",
       " 0.84,\n",
       " 0.8466667,\n",
       " 0.85333335,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.86,\n",
       " 0.87,\n",
       " 0.8666667,\n",
       " 0.8466667,\n",
       " 0.8333333,\n",
       " 0.8466667,\n",
       " 0.8333333,\n",
       " 0.80333334,\n",
       " 0.86333334,\n",
       " 0.86,\n",
       " 0.8566667,\n",
       " 0.8466667,\n",
       " 0.8433333,\n",
       " 0.85,\n",
       " 0.83666664,\n",
       " 0.86333334,\n",
       " 0.86,\n",
       " 0.86333334,\n",
       " 0.86,\n",
       " 0.85333335,\n",
       " 0.87333333,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.85,\n",
       " 0.85,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.8466667,\n",
       " 0.86333334,\n",
       " 0.8666667,\n",
       " 0.86333334,\n",
       " 0.87,\n",
       " 0.87333333,\n",
       " 0.85333335,\n",
       " 0.85333335,\n",
       " 0.8466667,\n",
       " 0.86333334,\n",
       " 0.87,\n",
       " 0.8433333,\n",
       " 0.8666667,\n",
       " 0.84,\n",
       " 0.86333334,\n",
       " 0.87666667,\n",
       " 0.86,\n",
       " 0.82666665,\n",
       " 0.83666664,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.87,\n",
       " 0.87333333,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.85,\n",
       " 0.87333333,\n",
       " 0.8433333,\n",
       " 0.87,\n",
       " 0.87333333,\n",
       " 0.8666667,\n",
       " 0.87333333,\n",
       " 0.83666664,\n",
       " 0.82,\n",
       " 0.87333333,\n",
       " 0.8566667,\n",
       " 0.8466667,\n",
       " 0.8566667,\n",
       " 0.8566667,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.87333333,\n",
       " 0.8566667,\n",
       " 0.8666667,\n",
       " 0.8566667,\n",
       " 0.87,\n",
       " 0.85333335,\n",
       " 0.83666664,\n",
       " 0.85333335,\n",
       " 0.86333334,\n",
       " 0.8566667,\n",
       " 0.87666667,\n",
       " 0.88,\n",
       " 0.86,\n",
       " 0.86333334,\n",
       " 0.86333334,\n",
       " 0.87,\n",
       " 0.87,\n",
       " 0.86333334,\n",
       " 0.87333333,\n",
       " 0.8566667,\n",
       " 0.85333335,\n",
       " 0.87666667,\n",
       " 0.86333334,\n",
       " 0.8666667,\n",
       " 0.86333334,\n",
       " 0.87,\n",
       " 0.8433333,\n",
       " 0.85333335,\n",
       " 0.87]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딕셔너리로 저장.\n",
    "history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         loss  accuracy  val_loss  val_accuracy\n",
      "0    7.082678  0.556667  2.645491      0.842105\n",
      "1    2.673541  0.830000  2.041678      0.842105\n",
      "2    1.703610  0.786667  1.092522      0.815789\n",
      "3    1.029593  0.773333  0.626164      0.802632\n",
      "4    0.676180  0.803333  0.687937      0.815789\n",
      "..        ...       ...       ...           ...\n",
      "495  0.359637  0.863333  0.587103      0.815789\n",
      "496  0.353697  0.870000  0.633356      0.828947\n",
      "497  0.346254  0.843333  0.557907      0.828947\n",
      "498  0.369258  0.853333  0.610558      0.828947\n",
      "499  0.324640  0.870000  0.675651      0.828947\n",
      "\n",
      "[500 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(history.history)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df)\n",
    "plt.xlim(0,30)\n",
    "plt.ylim(0.4,1)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 24)                432       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 200       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(24,input_shape=(17,), activation=\"relu\"))\n",
    "model2.add(Dense(8, activation=\"relu\"))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 환경 설정 (오차함수, 최적화함수)\n",
    "model2.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",\n",
    "               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 470 samples\n",
      "Epoch 1/500\n",
      "470/470 [==============================] - 0s 578us/sample - loss: 1.4236 - accuracy: 0.8511\n",
      "Epoch 2/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.6248 - accuracy: 0.7723\n",
      "Epoch 3/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.5280 - accuracy: 0.8468\n",
      "Epoch 4/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4849 - accuracy: 0.8277\n",
      "Epoch 5/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4748 - accuracy: 0.8319\n",
      "Epoch 6/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4666 - accuracy: 0.8489\n",
      "Epoch 7/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4691 - accuracy: 0.8468\n",
      "Epoch 8/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4596 - accuracy: 0.8468\n",
      "Epoch 9/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4596 - accuracy: 0.8468\n",
      "Epoch 10/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4455 - accuracy: 0.8468\n",
      "Epoch 11/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4447 - accuracy: 0.8511\n",
      "Epoch 12/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4381 - accuracy: 0.8511\n",
      "Epoch 13/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4294 - accuracy: 0.8511\n",
      "Epoch 14/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4327 - accuracy: 0.8511\n",
      "Epoch 15/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4248 - accuracy: 0.8511\n",
      "Epoch 16/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4233 - accuracy: 0.8511\n",
      "Epoch 17/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4204 - accuracy: 0.8511\n",
      "Epoch 18/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4248 - accuracy: 0.8511\n",
      "Epoch 19/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4228 - accuracy: 0.8511\n",
      "Epoch 20/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4173 - accuracy: 0.8511\n",
      "Epoch 21/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4202 - accuracy: 0.8511\n",
      "Epoch 22/500\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.86 - 0s 27us/sample - loss: 0.4203 - accuracy: 0.8511\n",
      "Epoch 23/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.4188 - accuracy: 0.8511\n",
      "Epoch 24/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4170 - accuracy: 0.8511\n",
      "Epoch 25/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4164 - accuracy: 0.8511\n",
      "Epoch 26/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4224 - accuracy: 0.8511\n",
      "Epoch 27/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4223 - accuracy: 0.8511\n",
      "Epoch 28/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4190 - accuracy: 0.8489\n",
      "Epoch 29/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4175 - accuracy: 0.8511\n",
      "Epoch 30/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4155 - accuracy: 0.8511\n",
      "Epoch 31/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4139 - accuracy: 0.8532\n",
      "Epoch 32/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4185 - accuracy: 0.8511\n",
      "Epoch 33/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4139 - accuracy: 0.8511\n",
      "Epoch 34/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.4150 - accuracy: 0.8511\n",
      "Epoch 35/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4179 - accuracy: 0.8511\n",
      "Epoch 36/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4158 - accuracy: 0.8511\n",
      "Epoch 37/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4127 - accuracy: 0.8489\n",
      "Epoch 38/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4122 - accuracy: 0.8489\n",
      "Epoch 39/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4149 - accuracy: 0.8532\n",
      "Epoch 40/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4153 - accuracy: 0.8511\n",
      "Epoch 41/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4121 - accuracy: 0.8511\n",
      "Epoch 42/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4096 - accuracy: 0.8511\n",
      "Epoch 43/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4189 - accuracy: 0.8511\n",
      "Epoch 44/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4218 - accuracy: 0.8511\n",
      "Epoch 45/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4125 - accuracy: 0.8511\n",
      "Epoch 46/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4076 - accuracy: 0.8511\n",
      "Epoch 47/500\n",
      "470/470 [==============================] - 0s 30us/sample - loss: 0.4121 - accuracy: 0.8511\n",
      "Epoch 48/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.4108 - accuracy: 0.8511\n",
      "Epoch 49/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4115 - accuracy: 0.8511\n",
      "Epoch 50/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4120 - accuracy: 0.8532\n",
      "Epoch 51/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4091 - accuracy: 0.8532\n",
      "Epoch 52/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4092 - accuracy: 0.8511\n",
      "Epoch 53/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4073 - accuracy: 0.8532\n",
      "Epoch 54/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4127 - accuracy: 0.8511\n",
      "Epoch 55/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.4109 - accuracy: 0.8489\n",
      "Epoch 56/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4118 - accuracy: 0.8511\n",
      "Epoch 57/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4099 - accuracy: 0.8511\n",
      "Epoch 58/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.4102 - accuracy: 0.8511\n",
      "Epoch 59/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4084 - accuracy: 0.8511\n",
      "Epoch 60/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.4093 - accuracy: 0.8532\n",
      "Epoch 61/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4072 - accuracy: 0.8511\n",
      "Epoch 62/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4076 - accuracy: 0.8511\n",
      "Epoch 63/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4085 - accuracy: 0.8511\n",
      "Epoch 64/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4078 - accuracy: 0.8489\n",
      "Epoch 65/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4110 - accuracy: 0.8532\n",
      "Epoch 66/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4099 - accuracy: 0.8511\n",
      "Epoch 67/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4066 - accuracy: 0.8532\n",
      "Epoch 68/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4090 - accuracy: 0.8532\n",
      "Epoch 69/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4082 - accuracy: 0.8511\n",
      "Epoch 70/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4079 - accuracy: 0.8511\n",
      "Epoch 71/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4062 - accuracy: 0.8532\n",
      "Epoch 72/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.4091 - accuracy: 0.8511\n",
      "Epoch 73/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4088 - accuracy: 0.8532\n",
      "Epoch 74/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4039 - accuracy: 0.8511\n",
      "Epoch 75/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4058 - accuracy: 0.8489\n",
      "Epoch 76/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4062 - accuracy: 0.8532\n",
      "Epoch 77/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4046 - accuracy: 0.8511\n",
      "Epoch 78/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4034 - accuracy: 0.8532\n",
      "Epoch 79/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4069 - accuracy: 0.8532\n",
      "Epoch 80/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4049 - accuracy: 0.8511\n",
      "Epoch 81/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4090 - accuracy: 0.8511\n",
      "Epoch 82/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4059 - accuracy: 0.8511\n",
      "Epoch 83/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4105 - accuracy: 0.8511\n",
      "Epoch 84/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4063 - accuracy: 0.8511\n",
      "Epoch 85/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4037 - accuracy: 0.8511\n",
      "Epoch 86/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4021 - accuracy: 0.8511\n",
      "Epoch 87/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4015 - accuracy: 0.8532\n",
      "Epoch 88/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4029 - accuracy: 0.8532\n",
      "Epoch 89/500\n",
      "470/470 [==============================] - 0s 22us/sample - loss: 0.4005 - accuracy: 0.8511\n",
      "Epoch 90/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4028 - accuracy: 0.8532\n",
      "Epoch 91/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4023 - accuracy: 0.8532\n",
      "Epoch 92/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4014 - accuracy: 0.8511\n",
      "Epoch 93/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4006 - accuracy: 0.8511\n",
      "Epoch 94/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4005 - accuracy: 0.8511\n",
      "Epoch 95/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4001 - accuracy: 0.8532\n",
      "Epoch 96/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4022 - accuracy: 0.8553\n",
      "Epoch 97/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.4003 - accuracy: 0.8511\n",
      "Epoch 98/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4026 - accuracy: 0.8532\n",
      "Epoch 99/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4024 - accuracy: 0.8511\n",
      "Epoch 100/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4016 - accuracy: 0.8532\n",
      "Epoch 101/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4000 - accuracy: 0.8553\n",
      "Epoch 102/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4009 - accuracy: 0.8511\n",
      "Epoch 103/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3972 - accuracy: 0.8532\n",
      "Epoch 104/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4029 - accuracy: 0.8532\n",
      "Epoch 105/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4018 - accuracy: 0.8553\n",
      "Epoch 106/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4006 - accuracy: 0.8511\n",
      "Epoch 107/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4027 - accuracy: 0.8553\n",
      "Epoch 108/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3989 - accuracy: 0.8532\n",
      "Epoch 109/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3975 - accuracy: 0.8553\n",
      "Epoch 110/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3968 - accuracy: 0.8532\n",
      "Epoch 111/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3995 - accuracy: 0.8511\n",
      "Epoch 112/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3982 - accuracy: 0.8532\n",
      "Epoch 113/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3973 - accuracy: 0.8532\n",
      "Epoch 114/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.4001 - accuracy: 0.8532\n",
      "Epoch 115/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4006 - accuracy: 0.8532\n",
      "Epoch 116/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4022 - accuracy: 0.8511\n",
      "Epoch 117/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4046 - accuracy: 0.8553\n",
      "Epoch 118/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4011 - accuracy: 0.8532\n",
      "Epoch 119/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3950 - accuracy: 0.8532\n",
      "Epoch 120/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4016 - accuracy: 0.8553\n",
      "Epoch 121/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.4026 - accuracy: 0.8532\n",
      "Epoch 122/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4155 - accuracy: 0.8553\n",
      "Epoch 123/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4071 - accuracy: 0.8553\n",
      "Epoch 124/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3933 - accuracy: 0.8553\n",
      "Epoch 125/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4000 - accuracy: 0.8532\n",
      "Epoch 126/500\n",
      "470/470 [==============================] - 0s 22us/sample - loss: 0.3970 - accuracy: 0.8532\n",
      "Epoch 127/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3983 - accuracy: 0.8532\n",
      "Epoch 128/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4011 - accuracy: 0.8553\n",
      "Epoch 129/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4021 - accuracy: 0.8553\n",
      "Epoch 130/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3971 - accuracy: 0.8532\n",
      "Epoch 131/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3995 - accuracy: 0.8511\n",
      "Epoch 132/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3933 - accuracy: 0.8553\n",
      "Epoch 133/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3949 - accuracy: 0.8553\n",
      "Epoch 134/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.4033 - accuracy: 0.8511\n",
      "Epoch 135/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.4041 - accuracy: 0.8553\n",
      "Epoch 136/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3997 - accuracy: 0.8532\n",
      "Epoch 137/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3944 - accuracy: 0.8553\n",
      "Epoch 138/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3956 - accuracy: 0.8553\n",
      "Epoch 139/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3950 - accuracy: 0.8553\n",
      "Epoch 140/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3931 - accuracy: 0.8553\n",
      "Epoch 141/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3976 - accuracy: 0.8553\n",
      "Epoch 142/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3933 - accuracy: 0.8553\n",
      "Epoch 143/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3983 - accuracy: 0.8553\n",
      "Epoch 144/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3979 - accuracy: 0.8553\n",
      "Epoch 145/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3931 - accuracy: 0.8553\n",
      "Epoch 146/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3949 - accuracy: 0.8553\n",
      "Epoch 147/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3908 - accuracy: 0.8553\n",
      "Epoch 148/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3931 - accuracy: 0.8553\n",
      "Epoch 149/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3932 - accuracy: 0.8553\n",
      "Epoch 150/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3931 - accuracy: 0.8553\n",
      "Epoch 151/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3953 - accuracy: 0.8553\n",
      "Epoch 152/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3950 - accuracy: 0.8553\n",
      "Epoch 153/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3939 - accuracy: 0.8553\n",
      "Epoch 154/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3936 - accuracy: 0.8553\n",
      "Epoch 155/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3907 - accuracy: 0.8553\n",
      "Epoch 156/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3931 - accuracy: 0.8553\n",
      "Epoch 157/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3953 - accuracy: 0.8553\n",
      "Epoch 158/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3956 - accuracy: 0.8553\n",
      "Epoch 159/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3902 - accuracy: 0.8553\n",
      "Epoch 160/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3979 - accuracy: 0.8553\n",
      "Epoch 161/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3925 - accuracy: 0.8553\n",
      "Epoch 162/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3923 - accuracy: 0.8553\n",
      "Epoch 163/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3930 - accuracy: 0.8553\n",
      "Epoch 164/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3891 - accuracy: 0.8553\n",
      "Epoch 165/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3910 - accuracy: 0.8553\n",
      "Epoch 166/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3947 - accuracy: 0.8553\n",
      "Epoch 167/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3944 - accuracy: 0.8532\n",
      "Epoch 168/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3983 - accuracy: 0.8553\n",
      "Epoch 169/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3971 - accuracy: 0.8532\n",
      "Epoch 170/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3882 - accuracy: 0.8553\n",
      "Epoch 171/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3919 - accuracy: 0.8553\n",
      "Epoch 172/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3892 - accuracy: 0.8553\n",
      "Epoch 173/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3872 - accuracy: 0.8553\n",
      "Epoch 174/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3887 - accuracy: 0.8553\n",
      "Epoch 175/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3899 - accuracy: 0.8553\n",
      "Epoch 176/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3908 - accuracy: 0.8553\n",
      "Epoch 177/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3968 - accuracy: 0.8553\n",
      "Epoch 178/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3920 - accuracy: 0.8553\n",
      "Epoch 179/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3964 - accuracy: 0.8553\n",
      "Epoch 180/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3918 - accuracy: 0.8553\n",
      "Epoch 181/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3885 - accuracy: 0.8553\n",
      "Epoch 182/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3875 - accuracy: 0.8553\n",
      "Epoch 183/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3913 - accuracy: 0.8553\n",
      "Epoch 184/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3906 - accuracy: 0.8553\n",
      "Epoch 185/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3974 - accuracy: 0.8553\n",
      "Epoch 186/500\n",
      "470/470 [==============================] - 0s 22us/sample - loss: 0.3895 - accuracy: 0.8553\n",
      "Epoch 187/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3913 - accuracy: 0.8553\n",
      "Epoch 188/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3882 - accuracy: 0.8553\n",
      "Epoch 189/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3871 - accuracy: 0.8553\n",
      "Epoch 190/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3847 - accuracy: 0.8553\n",
      "Epoch 191/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3890 - accuracy: 0.8553\n",
      "Epoch 192/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.4020 - accuracy: 0.8553\n",
      "Epoch 193/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3929 - accuracy: 0.8553\n",
      "Epoch 194/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3906 - accuracy: 0.8553\n",
      "Epoch 195/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3920 - accuracy: 0.8553\n",
      "Epoch 196/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3927 - accuracy: 0.8553\n",
      "Epoch 197/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3851 - accuracy: 0.8553\n",
      "Epoch 198/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3863 - accuracy: 0.8553\n",
      "Epoch 199/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3846 - accuracy: 0.8553\n",
      "Epoch 200/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3874 - accuracy: 0.8553\n",
      "Epoch 201/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3873 - accuracy: 0.8553\n",
      "Epoch 202/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3845 - accuracy: 0.8574\n",
      "Epoch 203/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3851 - accuracy: 0.8553\n",
      "Epoch 204/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3831 - accuracy: 0.8553\n",
      "Epoch 205/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3849 - accuracy: 0.8553\n",
      "Epoch 206/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3894 - accuracy: 0.8553\n",
      "Epoch 207/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3895 - accuracy: 0.8553\n",
      "Epoch 208/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3824 - accuracy: 0.8574\n",
      "Epoch 209/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3850 - accuracy: 0.8553\n",
      "Epoch 210/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3910 - accuracy: 0.8574\n",
      "Epoch 211/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3854 - accuracy: 0.8553\n",
      "Epoch 212/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3853 - accuracy: 0.8553\n",
      "Epoch 213/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3825 - accuracy: 0.8574\n",
      "Epoch 214/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3855 - accuracy: 0.8553\n",
      "Epoch 215/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3891 - accuracy: 0.8553\n",
      "Epoch 216/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3870 - accuracy: 0.8574\n",
      "Epoch 217/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3843 - accuracy: 0.8574\n",
      "Epoch 218/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3864 - accuracy: 0.8553\n",
      "Epoch 219/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3856 - accuracy: 0.8553\n",
      "Epoch 220/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3802 - accuracy: 0.8553\n",
      "Epoch 221/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3811 - accuracy: 0.8574\n",
      "Epoch 222/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3861 - accuracy: 0.8574\n",
      "Epoch 223/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3839 - accuracy: 0.8553\n",
      "Epoch 224/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3821 - accuracy: 0.8574\n",
      "Epoch 225/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3881 - accuracy: 0.8574\n",
      "Epoch 226/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3941 - accuracy: 0.8553\n",
      "Epoch 227/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3893 - accuracy: 0.8553\n",
      "Epoch 228/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3841 - accuracy: 0.8553\n",
      "Epoch 229/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3820 - accuracy: 0.8553\n",
      "Epoch 230/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3807 - accuracy: 0.8553\n",
      "Epoch 231/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.3806 - accuracy: 0.8553\n",
      "Epoch 232/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3787 - accuracy: 0.8574\n",
      "Epoch 233/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3789 - accuracy: 0.8553\n",
      "Epoch 234/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3781 - accuracy: 0.8574\n",
      "Epoch 235/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3797 - accuracy: 0.8574\n",
      "Epoch 236/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3852 - accuracy: 0.8553\n",
      "Epoch 237/500\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.5074 - accuracy: 0.76 - 0s 21us/sample - loss: 0.3817 - accuracy: 0.8574\n",
      "Epoch 238/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3813 - accuracy: 0.8553\n",
      "Epoch 239/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3811 - accuracy: 0.8553\n",
      "Epoch 240/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3808 - accuracy: 0.8553\n",
      "Epoch 241/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3795 - accuracy: 0.8553\n",
      "Epoch 242/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3780 - accuracy: 0.8553\n",
      "Epoch 243/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3831 - accuracy: 0.8553\n",
      "Epoch 244/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3758 - accuracy: 0.8553\n",
      "Epoch 245/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3784 - accuracy: 0.8574\n",
      "Epoch 246/500\n",
      "470/470 [==============================] - 0s 22us/sample - loss: 0.3745 - accuracy: 0.8574\n",
      "Epoch 247/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3742 - accuracy: 0.8574\n",
      "Epoch 248/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3788 - accuracy: 0.8553\n",
      "Epoch 249/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3795 - accuracy: 0.8574\n",
      "Epoch 250/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3779 - accuracy: 0.8553\n",
      "Epoch 251/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3752 - accuracy: 0.8574\n",
      "Epoch 252/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3749 - accuracy: 0.8553\n",
      "Epoch 253/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3749 - accuracy: 0.8574\n",
      "Epoch 254/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3789 - accuracy: 0.8553\n",
      "Epoch 255/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3752 - accuracy: 0.8574\n",
      "Epoch 256/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3777 - accuracy: 0.8596\n",
      "Epoch 257/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3781 - accuracy: 0.8553\n",
      "Epoch 258/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3756 - accuracy: 0.8574\n",
      "Epoch 259/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3796 - accuracy: 0.8553\n",
      "Epoch 260/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3776 - accuracy: 0.8596\n",
      "Epoch 261/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3763 - accuracy: 0.8553\n",
      "Epoch 262/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3758 - accuracy: 0.8596\n",
      "Epoch 263/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3750 - accuracy: 0.8553\n",
      "Epoch 264/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3743 - accuracy: 0.8553\n",
      "Epoch 265/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3757 - accuracy: 0.8596\n",
      "Epoch 266/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3712 - accuracy: 0.8596\n",
      "Epoch 267/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3726 - accuracy: 0.8574\n",
      "Epoch 268/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3710 - accuracy: 0.8596\n",
      "Epoch 269/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3749 - accuracy: 0.8574\n",
      "Epoch 270/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3721 - accuracy: 0.8596\n",
      "Epoch 271/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.3756 - accuracy: 0.8596\n",
      "Epoch 272/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3747 - accuracy: 0.8574\n",
      "Epoch 273/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.3744 - accuracy: 0.8574\n",
      "Epoch 274/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3695 - accuracy: 0.8617\n",
      "Epoch 275/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3712 - accuracy: 0.8617\n",
      "Epoch 276/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3696 - accuracy: 0.8617\n",
      "Epoch 277/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3706 - accuracy: 0.8638\n",
      "Epoch 278/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3799 - accuracy: 0.8574\n",
      "Epoch 279/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3779 - accuracy: 0.8574\n",
      "Epoch 280/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3843 - accuracy: 0.8574\n",
      "Epoch 281/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3764 - accuracy: 0.8574\n",
      "Epoch 282/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3710 - accuracy: 0.8553\n",
      "Epoch 283/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3789 - accuracy: 0.8596\n",
      "Epoch 284/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3727 - accuracy: 0.8574\n",
      "Epoch 285/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3764 - accuracy: 0.8617\n",
      "Epoch 286/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3682 - accuracy: 0.8596\n",
      "Epoch 287/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3675 - accuracy: 0.8596\n",
      "Epoch 288/500\n",
      "470/470 [==============================] - 0s 29us/sample - loss: 0.3665 - accuracy: 0.8596\n",
      "Epoch 289/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3659 - accuracy: 0.8617\n",
      "Epoch 290/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3716 - accuracy: 0.8617\n",
      "Epoch 291/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3685 - accuracy: 0.8574\n",
      "Epoch 292/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3692 - accuracy: 0.8617\n",
      "Epoch 293/500\n",
      "470/470 [==============================] - 0s 30us/sample - loss: 0.3690 - accuracy: 0.8638\n",
      "Epoch 294/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3695 - accuracy: 0.8574\n",
      "Epoch 295/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.3714 - accuracy: 0.8617\n",
      "Epoch 296/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.3698 - accuracy: 0.8596\n",
      "Epoch 297/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3718 - accuracy: 0.8574\n",
      "Epoch 298/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.3689 - accuracy: 0.8596\n",
      "Epoch 299/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3681 - accuracy: 0.8617\n",
      "Epoch 300/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3743 - accuracy: 0.8596\n",
      "Epoch 301/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3807 - accuracy: 0.8638\n",
      "Epoch 302/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3693 - accuracy: 0.8638\n",
      "Epoch 303/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3752 - accuracy: 0.8617\n",
      "Epoch 304/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3743 - accuracy: 0.8596\n",
      "Epoch 305/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3632 - accuracy: 0.8596\n",
      "Epoch 306/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3657 - accuracy: 0.8638\n",
      "Epoch 307/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3631 - accuracy: 0.8617\n",
      "Epoch 308/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3640 - accuracy: 0.8660\n",
      "Epoch 309/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3613 - accuracy: 0.8660\n",
      "Epoch 310/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3635 - accuracy: 0.8638\n",
      "Epoch 311/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3608 - accuracy: 0.8638\n",
      "Epoch 312/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3677 - accuracy: 0.8638\n",
      "Epoch 313/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3618 - accuracy: 0.8617\n",
      "Epoch 314/500\n",
      "470/470 [==============================] - 0s 22us/sample - loss: 0.3673 - accuracy: 0.8596\n",
      "Epoch 315/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3604 - accuracy: 0.8617\n",
      "Epoch 316/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3636 - accuracy: 0.8617\n",
      "Epoch 317/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3638 - accuracy: 0.8596\n",
      "Epoch 318/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3624 - accuracy: 0.8617\n",
      "Epoch 319/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3625 - accuracy: 0.8638\n",
      "Epoch 320/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3705 - accuracy: 0.8617\n",
      "Epoch 321/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3693 - accuracy: 0.8660\n",
      "Epoch 322/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3724 - accuracy: 0.8638\n",
      "Epoch 323/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3796 - accuracy: 0.8596\n",
      "Epoch 324/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3604 - accuracy: 0.8617\n",
      "Epoch 325/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3687 - accuracy: 0.8638\n",
      "Epoch 326/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3591 - accuracy: 0.8638\n",
      "Epoch 327/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3583 - accuracy: 0.8638\n",
      "Epoch 328/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3601 - accuracy: 0.8596\n",
      "Epoch 329/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3606 - accuracy: 0.8617\n",
      "Epoch 330/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3636 - accuracy: 0.8638\n",
      "Epoch 331/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3648 - accuracy: 0.8596\n",
      "Epoch 332/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3737 - accuracy: 0.8574\n",
      "Epoch 333/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3614 - accuracy: 0.8638\n",
      "Epoch 334/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3616 - accuracy: 0.8660\n",
      "Epoch 335/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3661 - accuracy: 0.8638\n",
      "Epoch 336/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3664 - accuracy: 0.8638\n",
      "Epoch 337/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3651 - accuracy: 0.8638\n",
      "Epoch 338/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3692 - accuracy: 0.8617\n",
      "Epoch 339/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3616 - accuracy: 0.8617\n",
      "Epoch 340/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3743 - accuracy: 0.8617\n",
      "Epoch 341/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3619 - accuracy: 0.8660\n",
      "Epoch 342/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3596 - accuracy: 0.8596\n",
      "Epoch 343/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3656 - accuracy: 0.8596\n",
      "Epoch 344/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3637 - accuracy: 0.8617\n",
      "Epoch 345/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3583 - accuracy: 0.8638\n",
      "Epoch 346/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3566 - accuracy: 0.8638\n",
      "Epoch 347/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3670 - accuracy: 0.8617\n",
      "Epoch 348/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3557 - accuracy: 0.8617\n",
      "Epoch 349/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3720 - accuracy: 0.8617\n",
      "Epoch 350/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3613 - accuracy: 0.8638\n",
      "Epoch 351/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3606 - accuracy: 0.8617\n",
      "Epoch 352/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3583 - accuracy: 0.8660\n",
      "Epoch 353/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3531 - accuracy: 0.8638\n",
      "Epoch 354/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3560 - accuracy: 0.8617\n",
      "Epoch 355/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3548 - accuracy: 0.8617\n",
      "Epoch 356/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3577 - accuracy: 0.8638\n",
      "Epoch 357/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3533 - accuracy: 0.8617\n",
      "Epoch 358/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3576 - accuracy: 0.8617\n",
      "Epoch 359/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3541 - accuracy: 0.8638\n",
      "Epoch 360/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3539 - accuracy: 0.8638\n",
      "Epoch 361/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3565 - accuracy: 0.8617\n",
      "Epoch 362/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3586 - accuracy: 0.8638\n",
      "Epoch 363/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3534 - accuracy: 0.8617\n",
      "Epoch 364/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3550 - accuracy: 0.8638\n",
      "Epoch 365/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3533 - accuracy: 0.8638\n",
      "Epoch 366/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3637 - accuracy: 0.8574\n",
      "Epoch 367/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3594 - accuracy: 0.8638\n",
      "Epoch 368/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3613 - accuracy: 0.8638\n",
      "Epoch 369/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3600 - accuracy: 0.8617\n",
      "Epoch 370/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3583 - accuracy: 0.8638\n",
      "Epoch 371/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3510 - accuracy: 0.8638\n",
      "Epoch 372/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3586 - accuracy: 0.8638\n",
      "Epoch 373/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3533 - accuracy: 0.8638\n",
      "Epoch 374/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3530 - accuracy: 0.8638\n",
      "Epoch 375/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3633 - accuracy: 0.8617\n",
      "Epoch 376/500\n",
      "470/470 [==============================] - 0s 40us/sample - loss: 0.3598 - accuracy: 0.8617\n",
      "Epoch 377/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3585 - accuracy: 0.8638\n",
      "Epoch 378/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3562 - accuracy: 0.8638\n",
      "Epoch 379/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3559 - accuracy: 0.8617\n",
      "Epoch 380/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3494 - accuracy: 0.8638\n",
      "Epoch 381/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3551 - accuracy: 0.8617\n",
      "Epoch 382/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3499 - accuracy: 0.8638\n",
      "Epoch 383/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3503 - accuracy: 0.8638\n",
      "Epoch 384/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3477 - accuracy: 0.8638\n",
      "Epoch 385/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3560 - accuracy: 0.8617\n",
      "Epoch 386/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3533 - accuracy: 0.8638\n",
      "Epoch 387/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3605 - accuracy: 0.8660\n",
      "Epoch 388/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3523 - accuracy: 0.8660\n",
      "Epoch 389/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3595 - accuracy: 0.8596\n",
      "Epoch 390/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3527 - accuracy: 0.8617\n",
      "Epoch 391/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3561 - accuracy: 0.8638\n",
      "Epoch 392/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3517 - accuracy: 0.8617\n",
      "Epoch 393/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3464 - accuracy: 0.8638\n",
      "Epoch 394/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3566 - accuracy: 0.8596\n",
      "Epoch 395/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3631 - accuracy: 0.8617\n",
      "Epoch 396/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3524 - accuracy: 0.8617\n",
      "Epoch 397/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3483 - accuracy: 0.8638\n",
      "Epoch 398/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3503 - accuracy: 0.8638\n",
      "Epoch 399/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3497 - accuracy: 0.8681\n",
      "Epoch 400/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3554 - accuracy: 0.8617\n",
      "Epoch 401/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3544 - accuracy: 0.8638\n",
      "Epoch 402/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3639 - accuracy: 0.8660\n",
      "Epoch 403/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3514 - accuracy: 0.8638\n",
      "Epoch 404/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3625 - accuracy: 0.8617\n",
      "Epoch 405/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3503 - accuracy: 0.8638\n",
      "Epoch 406/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3470 - accuracy: 0.8660\n",
      "Epoch 407/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3536 - accuracy: 0.8660\n",
      "Epoch 408/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3489 - accuracy: 0.8660\n",
      "Epoch 409/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3492 - accuracy: 0.8660\n",
      "Epoch 410/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3470 - accuracy: 0.8638\n",
      "Epoch 411/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3577 - accuracy: 0.8702\n",
      "Epoch 412/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3553 - accuracy: 0.8617\n",
      "Epoch 413/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3497 - accuracy: 0.8660\n",
      "Epoch 414/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3490 - accuracy: 0.8638\n",
      "Epoch 415/500\n",
      "470/470 [==============================] - 0s 29us/sample - loss: 0.3502 - accuracy: 0.8660\n",
      "Epoch 416/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3479 - accuracy: 0.8660\n",
      "Epoch 417/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3527 - accuracy: 0.8638\n",
      "Epoch 418/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3459 - accuracy: 0.8681\n",
      "Epoch 419/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3521 - accuracy: 0.8638\n",
      "Epoch 420/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3459 - accuracy: 0.8681\n",
      "Epoch 421/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3504 - accuracy: 0.8638\n",
      "Epoch 422/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3470 - accuracy: 0.8638\n",
      "Epoch 423/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3471 - accuracy: 0.8617\n",
      "Epoch 424/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3449 - accuracy: 0.8681\n",
      "Epoch 425/500\n",
      "470/470 [==============================] - 0s 27us/sample - loss: 0.3523 - accuracy: 0.8617\n",
      "Epoch 426/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3549 - accuracy: 0.8638\n",
      "Epoch 427/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3481 - accuracy: 0.8660\n",
      "Epoch 428/500\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.76 - 0s 25us/sample - loss: 0.3457 - accuracy: 0.8702\n",
      "Epoch 429/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3452 - accuracy: 0.8660\n",
      "Epoch 430/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3443 - accuracy: 0.8638\n",
      "Epoch 431/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3649 - accuracy: 0.8660\n",
      "Epoch 432/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3498 - accuracy: 0.8681\n",
      "Epoch 433/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3474 - accuracy: 0.8660\n",
      "Epoch 434/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3504 - accuracy: 0.8660\n",
      "Epoch 435/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3541 - accuracy: 0.8638\n",
      "Epoch 436/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3511 - accuracy: 0.8660\n",
      "Epoch 437/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3531 - accuracy: 0.8660\n",
      "Epoch 438/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3443 - accuracy: 0.8638\n",
      "Epoch 439/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3423 - accuracy: 0.8660\n",
      "Epoch 440/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3456 - accuracy: 0.8681\n",
      "Epoch 441/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3529 - accuracy: 0.8574\n",
      "Epoch 442/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3610 - accuracy: 0.8617\n",
      "Epoch 443/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3479 - accuracy: 0.8638\n",
      "Epoch 444/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3571 - accuracy: 0.8660\n",
      "Epoch 445/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3406 - accuracy: 0.8660\n",
      "Epoch 446/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3434 - accuracy: 0.8638\n",
      "Epoch 447/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3491 - accuracy: 0.8617\n",
      "Epoch 448/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3444 - accuracy: 0.8702\n",
      "Epoch 449/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3463 - accuracy: 0.8638\n",
      "Epoch 450/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3456 - accuracy: 0.8638\n",
      "Epoch 451/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3488 - accuracy: 0.8596\n",
      "Epoch 452/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3404 - accuracy: 0.8702\n",
      "Epoch 453/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3391 - accuracy: 0.8617\n",
      "Epoch 454/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3424 - accuracy: 0.8638\n",
      "Epoch 455/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3405 - accuracy: 0.8681\n",
      "Epoch 456/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3450 - accuracy: 0.8681\n",
      "Epoch 457/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3424 - accuracy: 0.8681\n",
      "Epoch 458/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3391 - accuracy: 0.8638\n",
      "Epoch 459/500\n",
      "470/470 [==============================] - 0s 28us/sample - loss: 0.3444 - accuracy: 0.8660\n",
      "Epoch 460/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3400 - accuracy: 0.8702\n",
      "Epoch 461/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3425 - accuracy: 0.8660\n",
      "Epoch 462/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3521 - accuracy: 0.8702\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3394 - accuracy: 0.8723\n",
      "Epoch 464/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3382 - accuracy: 0.8681\n",
      "Epoch 465/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3403 - accuracy: 0.8702\n",
      "Epoch 466/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3430 - accuracy: 0.8681\n",
      "Epoch 467/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3448 - accuracy: 0.8660\n",
      "Epoch 468/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3405 - accuracy: 0.8681\n",
      "Epoch 469/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3445 - accuracy: 0.8702\n",
      "Epoch 470/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3459 - accuracy: 0.8702\n",
      "Epoch 471/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3517 - accuracy: 0.8660\n",
      "Epoch 472/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3426 - accuracy: 0.8723\n",
      "Epoch 473/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3501 - accuracy: 0.8660\n",
      "Epoch 474/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3439 - accuracy: 0.8745\n",
      "Epoch 475/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3564 - accuracy: 0.8660\n",
      "Epoch 476/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3454 - accuracy: 0.8723\n",
      "Epoch 477/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3393 - accuracy: 0.8702\n",
      "Epoch 478/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3435 - accuracy: 0.8702\n",
      "Epoch 479/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3445 - accuracy: 0.8702\n",
      "Epoch 480/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3373 - accuracy: 0.8702\n",
      "Epoch 481/500\n",
      "470/470 [==============================] - 0s 22us/sample - loss: 0.3377 - accuracy: 0.8723\n",
      "Epoch 482/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3492 - accuracy: 0.8681\n",
      "Epoch 483/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3395 - accuracy: 0.8702\n",
      "Epoch 484/500\n",
      "470/470 [==============================] - 0s 24us/sample - loss: 0.3486 - accuracy: 0.8681\n",
      "Epoch 485/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3403 - accuracy: 0.8660\n",
      "Epoch 486/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3458 - accuracy: 0.8702\n",
      "Epoch 487/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3400 - accuracy: 0.8638\n",
      "Epoch 488/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3389 - accuracy: 0.8723\n",
      "Epoch 489/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3361 - accuracy: 0.8702\n",
      "Epoch 490/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3426 - accuracy: 0.8723\n",
      "Epoch 491/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3359 - accuracy: 0.8745\n",
      "Epoch 492/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3472 - accuracy: 0.8745\n",
      "Epoch 493/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3469 - accuracy: 0.8723\n",
      "Epoch 494/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3506 - accuracy: 0.8660\n",
      "Epoch 495/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3415 - accuracy: 0.8660\n",
      "Epoch 496/500\n",
      "470/470 [==============================] - 0s 25us/sample - loss: 0.3366 - accuracy: 0.8681\n",
      "Epoch 497/500\n",
      "470/470 [==============================] - 0s 26us/sample - loss: 0.3332 - accuracy: 0.8723\n",
      "Epoch 498/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3338 - accuracy: 0.8766\n",
      "Epoch 499/500\n",
      "470/470 [==============================] - 0s 23us/sample - loss: 0.3375 - accuracy: 0.8723\n",
      "Epoch 500/500\n",
      "470/470 [==============================] - 0s 21us/sample - loss: 0.3376 - accuracy: 0.8702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ba40cd9888>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X, Y, epochs=500, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 - 0s - loss: 0.3311 - accuracy: 0.8723\n",
      "\n",
      " Accuracy: 0.8723\n"
     ]
    }
   ],
   "source": [
    "# 결과 출력\n",
    "# evaluate() returns the loss value & metrics values for the model \n",
    "print(\"\\n Accuracy: %.4f\" % (model2.evaluate(X, Y, verbose=2))[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
