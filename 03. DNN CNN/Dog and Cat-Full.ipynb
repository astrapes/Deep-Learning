{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dataset의 일부를 이용한 개, 고양이 구분ㅡ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../dataset/cat_and_dog/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used for resize and in our model\n",
    "ROW, COL=96, 96\n",
    "dogs, cats=[],[]\n",
    "y_dogs, y_cats=[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_path=os.path.join(path, 'dog.*')\n",
    "cat_path=os.path.join(path, 'cat.*')\n",
    "len(glob(dog_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load some our dog image\n",
    "for dog_img in glob(dog_path):\n",
    "    dog=cv2.imread(dog_img)\n",
    "    dog=cv2.cvtColor(dog,cv2.COLOR_BGR2GRAY)\n",
    "    dog=cv2.resize(dog, (ROW, COL))\n",
    "    dog=image.img_to_array(dog)\n",
    "    dogs.append(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load some our dog image\n",
    "for cat_img in glob(cat_path):\n",
    "    cat=cv2.imread(cat_img)\n",
    "    cat=cv2.cvtColor(cat,cv2.COLOR_BGR2GRAY)\n",
    "    cat=cv2.resize(cat, (ROW, COL))\n",
    "    cat=image.img_to_array(cat)\n",
    "    cats.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['dog','cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just change the labels for 0 and 1\n",
    "y_dogs=[1 for item in enumerate(dogs)]\n",
    "y_cats=[0 for item in enumerate(cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting everything to Numpy array to fit in our model\n",
    "## them creating a X and target file like we used to see\n",
    "## in Machine and Deep Learning models\n",
    "dogs = np.asarray(dogs).astype('float32') / 255\n",
    "cats = np.asarray(cats).astype('float32') / 255\n",
    "y_dogs = np.asarray(y_dogs).astype('int32')\n",
    "y_cats = np.asarray(y_cats).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((dogs,cats), axis=0)\n",
    "y = np.concatenate((y_dogs, y_cats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 96, 96, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,104,225\n",
      "Trainable params: 19,104,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Here is our model as a CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', input_shape=(ROW, COL, 1), activation='relu'),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to save checkpoint to use later\n",
    "modelpath = \"model/dogs_vs_cats-cnn.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/200\n",
      "16000/16000 [==============================] - 241s 15ms/step - loss: 0.6936 - accuracy: 0.5346 - val_loss: 0.6817 - val_accuracy: 0.5630\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68165, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 2/200\n",
      "16000/16000 [==============================] - 237s 15ms/step - loss: 0.6377 - accuracy: 0.6367 - val_loss: 0.5805 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68165 to 0.58049, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 3/200\n",
      "16000/16000 [==============================] - 239s 15ms/step - loss: 0.5401 - accuracy: 0.7334 - val_loss: 0.5033 - val_accuracy: 0.7490\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58049 to 0.50331, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 4/200\n",
      "16000/16000 [==============================] - 239s 15ms/step - loss: 0.4578 - accuracy: 0.7904 - val_loss: 0.4937 - val_accuracy: 0.7665\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50331 to 0.49365, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 5/200\n",
      "16000/16000 [==============================] - 238s 15ms/step - loss: 0.3818 - accuracy: 0.8307 - val_loss: 0.4827 - val_accuracy: 0.7710\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49365 to 0.48266, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 6/200\n",
      "16000/16000 [==============================] - 239s 15ms/step - loss: 0.2688 - accuracy: 0.8879 - val_loss: 0.5592 - val_accuracy: 0.7595\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.48266\n",
      "Epoch 7/200\n",
      "16000/16000 [==============================] - 241s 15ms/step - loss: 0.1565 - accuracy: 0.9404 - val_loss: 0.7140 - val_accuracy: 0.7700\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.48266\n",
      "Epoch 8/200\n",
      "16000/16000 [==============================] - 240s 15ms/step - loss: 0.0810 - accuracy: 0.9711 - val_loss: 0.9286 - val_accuracy: 0.7703\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.48266\n",
      "Epoch 9/200\n",
      "16000/16000 [==============================] - 239s 15ms/step - loss: 0.0540 - accuracy: 0.9823 - val_loss: 1.1114 - val_accuracy: 0.7560\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.48266\n",
      "Epoch 10/200\n",
      "16000/16000 [==============================] - 239s 15ms/step - loss: 0.0428 - accuracy: 0.9859 - val_loss: 1.1895 - val_accuracy: 0.7555\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.48266\n",
      "Epoch 11/200\n",
      "16000/16000 [==============================] - 239s 15ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 1.4049 - val_accuracy: 0.7638\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.48266\n",
      "Epoch 12/200\n",
      "16000/16000 [==============================] - 240s 15ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 1.4184 - val_accuracy: 0.7665\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48266\n",
      "Epoch 13/200\n",
      "16000/16000 [==============================] - 238s 15ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 1.3928 - val_accuracy: 0.7617\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48266\n",
      "Epoch 14/200\n",
      "16000/16000 [==============================] - 238s 15ms/step - loss: 0.0168 - accuracy: 0.9944 - val_loss: 1.3408 - val_accuracy: 0.7635\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48266\n",
      "Epoch 15/200\n",
      "16000/16000 [==============================] - 240s 15ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 1.3204 - val_accuracy: 0.7600\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25fa4ebf3c8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=200, validation_split=0.2,shuffle=True,\n",
    "          callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model('model/dogs_vs_cats-cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ACCURACY: 0.77120\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('MODEL ACCURACY: %.5f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
