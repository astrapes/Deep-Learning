{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dataset의 일부를 이용한 개, 고양이 구분ㅡ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os, cv2, random\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 406532672563718143\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6586313605\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13164576705728937217\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../dataset/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## used for resize and in our model\n",
    "ROW, COL=96, 96\n",
    "dogs, cats=[],[]\n",
    "y_dogs, y_cats=[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_path=os.path.join(path, 'dog.*')\n",
    "cat_path=os.path.join(path, 'cat.*')\n",
    "len(glob(dog_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load some our dog image\n",
    "for dog_img in glob(dog_path):\n",
    "    dog=cv2.imread(dog_img)\n",
    "    dog=cv2.cvtColor(dog,cv2.COLOR_BGR2GRAY)\n",
    "    dog=cv2.resize(dog, (ROW, COL))\n",
    "    dog=image.img_to_array(dog)\n",
    "    dogs.append(dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load some our dog image\n",
    "for cat_img in glob(cat_path):\n",
    "    cat=cv2.imread(cat_img)\n",
    "    cat=cv2.cvtColor(cat,cv2.COLOR_BGR2GRAY)\n",
    "    cat=cv2.resize(cat, (ROW, COL))\n",
    "    cat=image.img_to_array(cat)\n",
    "    cats.append(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['dog','cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just change the labels for 0 and 1\n",
    "y_dogs=[1 for item in enumerate(dogs)]\n",
    "y_cats=[0 for item in enumerate(cats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting everything to Numpy array to fit in our model\n",
    "## them creating a X and target file like we used to see\n",
    "## in Machine and Deep Learning models\n",
    "dogs = np.asarray(dogs).astype('float32') / 255\n",
    "cats = np.asarray(cats).astype('float32') / 255\n",
    "y_dogs = np.asarray(y_dogs).astype('int32')\n",
    "y_cats = np.asarray(y_cats).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((dogs,cats), axis=0)\n",
    "y = np.concatenate((y_dogs, y_cats), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(x,y,test_size=0.2,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 96, 96, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 48, 48, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               18874880  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 19,104,225\n",
      "Trainable params: 19,104,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Here is our model as a CNN\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), padding='same', input_shape=(ROW, COL, 1), activation='relu'),\n",
    "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Dropout(.25),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to save checkpoint to use later\n",
    "modelpath = \"model/dogs_vs_cats-cnn.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/1000\n",
      "16000/16000 [==============================] - 11s 714us/step - loss: 0.6909 - accuracy: 0.5318 - val_loss: 0.6848 - val_accuracy: 0.5472\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68483, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 2/1000\n",
      "16000/16000 [==============================] - 9s 582us/step - loss: 0.6470 - accuracy: 0.6235 - val_loss: 0.5834 - val_accuracy: 0.6952\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68483 to 0.58344, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 3/1000\n",
      "16000/16000 [==============================] - 9s 588us/step - loss: 0.5700 - accuracy: 0.7099 - val_loss: 0.5346 - val_accuracy: 0.7283\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58344 to 0.53459, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 4/1000\n",
      "16000/16000 [==============================] - 9s 580us/step - loss: 0.4750 - accuracy: 0.7721 - val_loss: 0.4894 - val_accuracy: 0.7715\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.53459 to 0.48940, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 5/1000\n",
      "16000/16000 [==============================] - 9s 579us/step - loss: 0.3949 - accuracy: 0.8220 - val_loss: 0.4850 - val_accuracy: 0.7713\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48940 to 0.48501, saving model to model/dogs_vs_cats-cnn.hdf5\n",
      "Epoch 6/1000\n",
      "16000/16000 [==============================] - 9s 582us/step - loss: 0.3045 - accuracy: 0.8717 - val_loss: 0.5237 - val_accuracy: 0.7853\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.48501\n",
      "Epoch 7/1000\n",
      "16000/16000 [==============================] - 9s 581us/step - loss: 0.1853 - accuracy: 0.9266 - val_loss: 0.6376 - val_accuracy: 0.7903\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.48501\n",
      "Epoch 8/1000\n",
      "16000/16000 [==============================] - 9s 583us/step - loss: 0.0975 - accuracy: 0.9651 - val_loss: 0.8285 - val_accuracy: 0.7742\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.48501\n",
      "Epoch 9/1000\n",
      "16000/16000 [==============================] - 9s 580us/step - loss: 0.0641 - accuracy: 0.9770 - val_loss: 0.9968 - val_accuracy: 0.7673\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.48501\n",
      "Epoch 10/1000\n",
      "16000/16000 [==============================] - 9s 579us/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 1.1904 - val_accuracy: 0.7785\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.48501\n",
      "Epoch 11/1000\n",
      "16000/16000 [==============================] - 9s 584us/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 1.2254 - val_accuracy: 0.7760\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.48501\n",
      "Epoch 12/1000\n",
      "16000/16000 [==============================] - 9s 580us/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 1.2481 - val_accuracy: 0.7763\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48501\n",
      "Epoch 13/1000\n",
      "16000/16000 [==============================] - 9s 584us/step - loss: 0.0117 - accuracy: 0.9963 - val_loss: 1.4731 - val_accuracy: 0.7822\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48501\n",
      "Epoch 14/1000\n",
      "16000/16000 [==============================] - 9s 580us/step - loss: 0.0212 - accuracy: 0.9925 - val_loss: 1.1924 - val_accuracy: 0.7728\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48501\n",
      "Epoch 15/1000\n",
      "16000/16000 [==============================] - 9s 583us/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 1.4822 - val_accuracy: 0.7732\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17ead296a88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=1000, validation_split=0.2,shuffle=True,\n",
    "          callbacks=[checkpointer, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = load_model('model/dogs_vs_cats-cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL ACCURACY: 0.78260\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('MODEL ACCURACY: %.5f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
